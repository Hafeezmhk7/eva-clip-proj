2025-07-09 19:39:56,151 - __main__ - INFO - ================================================================================
2025-07-09 19:39:56,152 - __main__ - INFO - BLIP3-o DiT Training with Flow Matching
2025-07-09 19:39:56,152 - __main__ - INFO - ================================================================================
2025-07-09 19:39:56,156 - __main__ - ERROR - Training failed with error: CLIP dimension must match your embeddings (1024 for ViT-L/14)
2025-07-09 19:39:56,156 - __main__ - ERROR - Full traceback:
2025-07-09 19:39:56,158 - __main__ - ERROR - Traceback (most recent call last):
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/train_blip3o_dit.py", line 311, in main
    save_configs(args, output_dir)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/train_blip3o_dit.py", line 262, in save_configs
    flow_config = create_flow_matching_config(args)
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/train_blip3o_dit.py", line 228, in create_flow_matching_config
    return FlowMatchingConfig(
        sigma_min=args.sigma_min,
    ...<5 lines>...
        schedule_type=args.schedule_type,
    )
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/src/modules/config/blip3o_config.py", line 179, in __init__
    assert clip_dim == 1024, "CLIP dimension must match your embeddings (1024 for ViT-L/14)"
           ^^^^^^^^^^^^^^^^
AssertionError: CLIP dimension must match your embeddings (1024 for ViT-L/14)

2025-07-09 19:45:30,449 - __main__ - INFO - ================================================================================
2025-07-09 19:45:30,449 - __main__ - INFO - BLIP3-o DiT Training with Flow Matching
2025-07-09 19:45:30,449 - __main__ - INFO - ================================================================================
2025-07-09 19:45:30,453 - __main__ - INFO - Configurations saved to debug_checkpoints
2025-07-09 19:45:30,453 - __main__ - INFO - CUDA not available, using CPU
2025-07-09 19:45:30,453 - __main__ - INFO - Using embeddings from: embeddings/fixed_grid_embeddings.pkl
2025-07-09 19:45:30,453 - __main__ - INFO - Creating model...
2025-07-09 19:46:38,826 - __main__ - INFO - Model created successfully:
2025-07-09 19:46:38,838 - __main__ - INFO -   Total parameters: 2,021,344,768
2025-07-09 19:46:38,838 - __main__ - INFO -   Trainable parameters: 2,021,344,768
2025-07-09 19:46:38,838 - __main__ - INFO -   Memory footprint: 7710.8 MB
2025-07-09 19:46:38,839 - __main__ - INFO -   Model dimensions: CLIP=1024, EVA=4096, Hidden=1792
2025-07-09 19:46:38,839 - __main__ - INFO - Creating flow matching loss...
2025-07-09 19:46:38,849 - __main__ - INFO - Creating datasets...
2025-07-09 19:46:38,864 - src.modules.datasets.blip3o_dataset - INFO - Loading embeddings from embeddings/fixed_grid_embeddings.pkl
2025-07-09 19:46:41,873 - src.modules.datasets.blip3o_dataset - INFO - Validated embeddings: EVA torch.Size([80, 64, 4096]), CLIP torch.Size([80, 64, 1024])
2025-07-09 19:46:41,874 - src.modules.datasets.blip3o_dataset - INFO - Loaded 80 embedding pairs
2025-07-09 19:46:42,151 - src.modules.datasets.blip3o_dataset - INFO - Using train split: 72 samples
2025-07-09 19:46:42,152 - src.modules.datasets.blip3o_dataset - WARNING - Subset size 1000 >= dataset size 72
2025-07-09 19:46:42,153 - src.modules.datasets.blip3o_dataset - INFO - Dataset created with 72 samples
2025-07-09 19:46:42,153 - src.modules.datasets.blip3o_dataset - INFO - EVA-CLIP embeddings shape: torch.Size([72, 64, 4096])
2025-07-09 19:46:42,153 - src.modules.datasets.blip3o_dataset - INFO - CLIP embeddings shape: torch.Size([72, 64, 1024])
2025-07-09 19:46:42,153 - src.modules.datasets.blip3o_dataset - INFO - Split: train
2025-07-09 19:46:42,153 - src.modules.datasets.blip3o_dataset - INFO - Normalization - EVA: False, CLIP: False
2025-07-09 19:46:42,266 - src.modules.datasets.blip3o_dataset - INFO - Loading embeddings from embeddings/fixed_grid_embeddings.pkl
2025-07-09 19:46:42,819 - src.modules.datasets.blip3o_dataset - INFO - Validated embeddings: EVA torch.Size([80, 64, 4096]), CLIP torch.Size([80, 64, 1024])
2025-07-09 19:46:42,820 - src.modules.datasets.blip3o_dataset - INFO - Loaded 80 embedding pairs
2025-07-09 19:46:42,825 - src.modules.datasets.blip3o_dataset - INFO - Using eval split: 8 samples
2025-07-09 19:46:42,825 - src.modules.datasets.blip3o_dataset - WARNING - Subset size 1000 >= dataset size 8
2025-07-09 19:46:42,826 - src.modules.datasets.blip3o_dataset - INFO - Dataset created with 8 samples
2025-07-09 19:46:42,826 - src.modules.datasets.blip3o_dataset - INFO - EVA-CLIP embeddings shape: torch.Size([8, 64, 4096])
2025-07-09 19:46:42,826 - src.modules.datasets.blip3o_dataset - INFO - CLIP embeddings shape: torch.Size([8, 64, 1024])
2025-07-09 19:46:42,826 - src.modules.datasets.blip3o_dataset - INFO - Split: eval
2025-07-09 19:46:42,826 - src.modules.datasets.blip3o_dataset - INFO - Normalization - EVA: False, CLIP: False
2025-07-09 19:46:42,827 - __main__ - INFO - Datasets created:
2025-07-09 19:46:42,827 - __main__ - INFO -   Training samples: 72
2025-07-09 19:46:42,828 - __main__ - INFO -   Evaluation samples: 8
2025-07-09 19:46:42,828 - __main__ - INFO -   Training batches per epoch: 5
2025-07-09 19:46:42,854 - __main__ - ERROR - Training failed with error: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'
2025-07-09 19:46:42,855 - __main__ - ERROR - Full traceback:
2025-07-09 19:46:42,989 - __main__ - ERROR - Traceback (most recent call last):
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/train_blip3o_dit.py", line 386, in main
    training_args = create_blip3o_training_args(
        output_dir=str(output_dir),
    ...<12 lines>...
        dataloader_num_workers=args.num_workers,
    )
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/src/modules/trainers/blip3o_trainer.py", line 556, in create_blip3o_training_args
    return TrainingArguments(
        output_dir=output_dir,
    ...<23 lines>...
        **kwargs
    )
TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'

2025-07-09 19:51:19,012 - __main__ - INFO - ================================================================================
2025-07-09 19:51:19,013 - __main__ - INFO - BLIP3-o DiT Training with Flow Matching
2025-07-09 19:51:19,013 - __main__ - INFO - ================================================================================
2025-07-09 19:51:19,019 - __main__ - INFO - Configurations saved to debug_checkpoints
2025-07-09 19:51:19,019 - __main__ - INFO - CUDA not available, using CPU
2025-07-09 19:51:19,019 - __main__ - INFO - Using embeddings from: embeddings/fixed_grid_embeddings.pkl
2025-07-09 19:51:19,019 - __main__ - INFO - Creating model...
2025-07-09 19:52:29,349 - __main__ - INFO - Model created successfully:
2025-07-09 19:52:29,358 - __main__ - INFO -   Total parameters: 2,021,344,768
2025-07-09 19:52:29,358 - __main__ - INFO -   Trainable parameters: 2,021,344,768
2025-07-09 19:52:29,358 - __main__ - INFO -   Memory footprint: 7710.8 MB
2025-07-09 19:52:29,359 - __main__ - INFO -   Model dimensions: CLIP=1024, EVA=4096, Hidden=1792
2025-07-09 19:52:29,359 - __main__ - INFO - Creating flow matching loss...
2025-07-09 19:52:29,369 - __main__ - INFO - Creating datasets...
2025-07-09 19:52:29,383 - src.modules.datasets.blip3o_dataset - INFO - Loading embeddings from embeddings/fixed_grid_embeddings.pkl
2025-07-09 19:52:31,545 - src.modules.datasets.blip3o_dataset - INFO - Validated embeddings: EVA torch.Size([80, 64, 4096]), CLIP torch.Size([80, 64, 1024])
2025-07-09 19:52:31,546 - src.modules.datasets.blip3o_dataset - INFO - Loaded 80 embedding pairs
2025-07-09 19:52:31,654 - src.modules.datasets.blip3o_dataset - INFO - Using train split: 72 samples
2025-07-09 19:52:31,655 - src.modules.datasets.blip3o_dataset - WARNING - Subset size 1000 >= dataset size 72
2025-07-09 19:52:31,749 - src.modules.datasets.blip3o_dataset - INFO - Dataset created with 72 samples
2025-07-09 19:52:31,749 - src.modules.datasets.blip3o_dataset - INFO - EVA-CLIP embeddings shape: torch.Size([72, 64, 4096])
2025-07-09 19:52:31,750 - src.modules.datasets.blip3o_dataset - INFO - CLIP embeddings shape: torch.Size([72, 64, 1024])
2025-07-09 19:52:31,750 - src.modules.datasets.blip3o_dataset - INFO - Split: train
2025-07-09 19:52:31,750 - src.modules.datasets.blip3o_dataset - INFO - Normalization - EVA: False, CLIP: False
2025-07-09 19:52:31,780 - src.modules.datasets.blip3o_dataset - INFO - Loading embeddings from embeddings/fixed_grid_embeddings.pkl
2025-07-09 19:52:32,326 - src.modules.datasets.blip3o_dataset - INFO - Validated embeddings: EVA torch.Size([80, 64, 4096]), CLIP torch.Size([80, 64, 1024])
2025-07-09 19:52:32,326 - src.modules.datasets.blip3o_dataset - INFO - Loaded 80 embedding pairs
2025-07-09 19:52:32,329 - src.modules.datasets.blip3o_dataset - INFO - Using eval split: 8 samples
2025-07-09 19:52:32,329 - src.modules.datasets.blip3o_dataset - WARNING - Subset size 1000 >= dataset size 8
2025-07-09 19:52:32,329 - src.modules.datasets.blip3o_dataset - INFO - Dataset created with 8 samples
2025-07-09 19:52:32,329 - src.modules.datasets.blip3o_dataset - INFO - EVA-CLIP embeddings shape: torch.Size([8, 64, 4096])
2025-07-09 19:52:32,329 - src.modules.datasets.blip3o_dataset - INFO - CLIP embeddings shape: torch.Size([8, 64, 1024])
2025-07-09 19:52:32,329 - src.modules.datasets.blip3o_dataset - INFO - Split: eval
2025-07-09 19:52:32,330 - src.modules.datasets.blip3o_dataset - INFO - Normalization - EVA: False, CLIP: False
2025-07-09 19:52:32,330 - __main__ - INFO - Datasets created:
2025-07-09 19:52:32,330 - __main__ - INFO -   Training samples: 72
2025-07-09 19:52:32,330 - __main__ - INFO -   Evaluation samples: 8
2025-07-09 19:52:32,331 - __main__ - INFO -   Training batches per epoch: 5
2025-07-09 19:52:32,575 - __main__ - INFO - Creating trainer...
2025-07-09 19:52:32,758 - src.modules.trainers.blip3o_trainer - INFO - BLIP3-o trainer initialized
2025-07-09 19:52:32,760 - src.modules.trainers.blip3o_trainer - INFO - Model parameters: 2,021,344,768
2025-07-09 19:52:32,762 - src.modules.trainers.blip3o_trainer - INFO - Trainable parameters: 2,021,344,768
2025-07-09 19:52:32,762 - __main__ - INFO - Training Summary:
2025-07-09 19:52:32,763 - __main__ - INFO -   Epochs: 2
2025-07-09 19:52:32,763 - __main__ - INFO -   Steps per epoch: 5
2025-07-09 19:52:32,763 - __main__ - INFO -   Total steps: 10
2025-07-09 19:52:32,763 - __main__ - INFO -   Batch size: 16
2025-07-09 19:52:32,763 - __main__ - INFO -   Learning rate: 0.0001
2025-07-09 19:52:32,763 - __main__ - INFO -   Weight decay: 0.01
2025-07-09 19:52:32,763 - __main__ - INFO -   Gradient accumulation: 1
2025-07-09 19:52:32,764 - __main__ - INFO -   Mixed precision: fp32
2025-07-09 19:52:32,764 - __main__ - INFO -   Output directory: debug_checkpoints
2025-07-09 19:52:32,764 - __main__ - INFO -   3D RoPE: Enabled with proper spatial-temporal encoding
2025-07-09 19:52:32,764 - __main__ - INFO - Starting training...
2025-07-09 19:52:32,764 - __main__ - INFO - ================================================================================
2025-07-09 19:52:35,699 - src.modules.trainers.blip3o_trainer - INFO - Training dataloader: 5 batches
2025-07-09 19:52:35,699 - src.modules.trainers.blip3o_trainer - INFO - Batch size: None
2025-07-09 19:52:35,699 - __main__ - ERROR - Training failed with error: unsupported operand type(s) for *: 'int' and 'NoneType'
2025-07-09 19:52:35,699 - __main__ - ERROR - Full traceback:
2025-07-09 19:52:35,702 - __main__ - ERROR - Traceback (most recent call last):
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/train_blip3o_dit.py", line 447, in main
    trainer.train(resume_from_checkpoint=resume_from_checkpoint)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/transformers/trainer.py", line 2206, in train
    return inner_training_loop(
        args=args,
    ...<2 lines>...
        ignore_keys_for_eval=ignore_keys_for_eval,
    )
  File "/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/transformers/trainer.py", line 2256, in _inner_training_loop
    train_dataloader = self.get_train_dataloader()
  File "/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/src/modules/trainers/blip3o_trainer.py", line 494, in get_train_dataloader
    logger.info(f"Total training samples per epoch: {len(dataloader) * dataloader.batch_size}")
                                                     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~
TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'

