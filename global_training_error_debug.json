{
  "error": "Caught TypeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\nTypeError: GlobalBLIP3oDiTModel.forward() got an unexpected keyword argument 'hidden_states'\n",
  "traceback": "Traceback (most recent call last):\n  File \"/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/src/modules/trainers/global_blip3o_trainer.py\", line 295, in compute_loss\n    model_output = model(\n        hidden_states=clip_embeddings,\n    ...<2 lines>...\n        return_dict=False\n    )\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/data_parallel.py\", line 194, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/data_parallel.py\", line 213, in parallel_apply\n    return parallel_apply(\n        replicas, inputs, kwargs, self.device_ids[: len(replicas)]\n    )\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/parallel_apply.py\", line 127, in parallel_apply\n    output.reraise()\n    ~~~~~~~~~~~~~~^^\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/_utils.py\", line 750, in reraise\n    raise exception\nTypeError: Caught TypeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\nTypeError: GlobalBLIP3oDiTModel.forward() got an unexpected keyword argument 'hidden_states'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/train_global_blip3o_multi_gpu.py\", line 539, in main\n    train_result = trainer.train()\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/transformers/trainer.py\", line 2206, in train\n    return inner_training_loop(\n        args=args,\n    ...<2 lines>...\n        ignore_keys_for_eval=ignore_keys_for_eval,\n    )\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/transformers/trainer.py\", line 2548, in _inner_training_loop\n    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/transformers/trainer.py\", line 3749, in training_step\n    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n  File \"/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/src/modules/trainers/global_blip3o_trainer.py\", line 313, in compute_loss\n    raise e\n  File \"/gpfs/home1/scur2711/eva-clip-flow-matching/eva-clip-v3/src/modules/trainers/global_blip3o_trainer.py\", line 188, in compute_loss\n    model_output = model(\n        hidden_states=noisy_clip,\n    ...<2 lines>...\n        return_dict=False\n    )\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/data_parallel.py\", line 194, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/data_parallel.py\", line 213, in parallel_apply\n    return parallel_apply(\n        replicas, inputs, kwargs, self.device_ids[: len(replicas)]\n    )\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/parallel_apply.py\", line 127, in parallel_apply\n    output.reraise()\n    ~~~~~~~~~~~~~~^^\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/_utils.py\", line 750, in reraise\n    raise exception\nTypeError: Caught TypeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/home/scur2711/.conda/envs/eva_clip_env/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\nTypeError: GlobalBLIP3oDiTModel.forward() got an unexpected keyword argument 'hidden_states'\n\n",
  "gpu_info": {
    "cuda_available": true,
    "gpu_count": 3,
    "gpu_names": [
      "NVIDIA H100",
      "NVIDIA H100",
      "NVIDIA H100"
    ],
    "memory_total": [
      93.1114501953125,
      93.1114501953125,
      93.1114501953125
    ],
    "slurm_allocation": "3",
    "cuda_visible_devices": "0,1,2",
    "issues": [],
    "recommendations": []
  },
  "environment": {
    "CUDA_VISIBLE_DEVICES": "0,1,2",
    "SLURM_GPUS": "3",
    "WORLD_SIZE": null,
    "LOCAL_RANK": null
  },
  "timestamp": "2025-07-22T13:30:01.785089",
  "training_type": "global"
}