#!/bin/bash
#SBATCH --job-name=blip3o_cpu_eval
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=32
#SBATCH --time=6:00:00
#SBATCH --mem=64G
#SBATCH --output=./slurm_out/blip3o_cpu_eval_%j.out
#SBATCH --error=./slurm_out/blip3o_cpu_eval_%j.err

# =============================================================================
# CPU-OPTIMIZED BLIP3-o Evaluation Job for Snellius
# Optimized for CPU-only evaluation with embeddings
# =============================================================================

echo "💻 CPU-Optimized BLIP3-o Evaluation on Snellius"
echo "============================================================="
echo "🎯 CPU CONFIGURATION:"
echo "  ✅ Partition: CPU (no GPU required)"
echo "  ✅ CPUs: 32 cores for parallel processing"
echo "  ✅ Memory: 64GB for large embedding processing"
echo "  ✅ Time: 6 hours (generous for CPU evaluation)"
echo "  ✅ CUDA disabled - pure CPU evaluation"
echo "============================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "CPU Info: $(lscpu | grep 'Model name' | head -1)"
echo "Available CPUs: $(nproc)"
echo "Available Memory: $(free -h | grep Mem | awk '{print $2}')"
echo "============================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment for CPU-only processing
module purge
module load 2024
module load Miniconda3/24.7.1-0
# NOTE: No CUDA module needed for CPU evaluation

# Activate environment
source activate eva_clip_env

# CPU-OPTIMIZED: Set environment variables for optimal CPU performance
export OMP_NUM_THREADS=16  # Use half the allocated CPUs
export MKL_NUM_THREADS=16  # Intel MKL optimization
export OPENBLAS_NUM_THREADS=16  # OpenBLAS optimization
export NUMEXPR_NUM_THREADS=16  # NumExpr optimization

# Disable CUDA completely
export CUDA_VISIBLE_DEVICES=""
export TORCH_USE_CUDA_DSA=0

echo "🔧 CPU Optimization Settings:"
echo "   OMP_NUM_THREADS: $OMP_NUM_THREADS"
echo "   MKL_NUM_THREADS: $MKL_NUM_THREADS"
echo "   CUDA_VISIBLE_DEVICES: '$CUDA_VISIBLE_DEVICES' (disabled)"

# Configuration - UPDATE THESE PATHS FOR YOUR SETUP
MODEL_PATH="/scratch-shared/scur2711/blip3o_workspace/checkpoints/blip3o_fixed_patch_only_13283695_20250724_165821"
EMBEDDINGS_DIR="/scratch-shared/scur2711/blip3o_workspace/embeddings/chunked_256_tokens"
OUTPUT_DIR="./cpu_eval_results_$(date +%Y%m%d_%H%M%S)"
TRAINING_MODE="auto"

# CPU-OPTIMIZED: Smaller defaults for CPU evaluation
NUM_SAMPLES=500          # Reduced for CPU (can increase if time permits)
BATCH_SIZE=4             # Smaller batch size for CPU memory
NUM_INFERENCE_STEPS=25   # Reduced inference steps for CPU speed
CPU_THREADS=16           # Explicit CPU thread control

# Create directories
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo ""
echo "⚙️ CPU Evaluation Configuration:"
echo "============================"
echo "Model Path: $MODEL_PATH"
echo "Embeddings: $EMBEDDINGS_DIR"
echo "Output: $OUTPUT_DIR"
echo "Training Mode: $TRAINING_MODE"
echo "Samples: $NUM_SAMPLES (CPU-optimized)"
echo "Batch Size: $BATCH_SIZE (CPU-optimized)"
echo "Inference Steps: $NUM_INFERENCE_STEPS (CPU-optimized)"
echo "CPU Threads: $CPU_THREADS"
echo ""

# Verify paths exist
echo "🔍 Verifying paths..."
echo "==================="

# Check model path
if [ ! -d "$MODEL_PATH" ]; then
    echo "❌ ERROR: Model path not found: $MODEL_PATH"
    echo "Available checkpoints:"
    ls -la "/scratch-shared/scur2711/blip3o_workspace/checkpoints/" 2>/dev/null || echo "No checkpoints directory found"
    exit 1
else
    echo "✅ Model path verified: $MODEL_PATH"
    echo "   Model files:"
    ls -la "$MODEL_PATH"/*.{bin,safetensors,json} 2>/dev/null | head -5
fi

# Check embeddings path
if [ ! -d "$EMBEDDINGS_DIR" ]; then
    echo "❌ ERROR: Embeddings path not found: $EMBEDDINGS_DIR"
    echo "Available embeddings:"
    ls -la "/scratch-shared/scur2711/blip3o_workspace/embeddings/" 2>/dev/null || echo "No embeddings directory found"
    exit 1
else
    echo "✅ Embeddings path verified: $EMBEDDINGS_DIR"
    if [ -f "$EMBEDDINGS_DIR/embeddings_manifest.json" ]; then
        echo "   Manifest found:"
        head -10 "$EMBEDDINGS_DIR/embeddings_manifest.json"
    fi
fi

# Check evaluation script
if [ ! -f "eval_blip3o_patch_similarity.py" ]; then
    echo "❌ ERROR: Evaluation script not found: eval_blip3o_patch_similarity.py"
    echo "Available Python files:"
    ls -la *.py
    exit 1
else
    echo "✅ Evaluation script verified: eval_blip3o_patch_similarity.py"
fi

echo ""
echo "🚀 Starting CPU-Optimized Evaluation..."
echo "======================================"
echo "This will perform comprehensive cosine similarity evaluation:"
echo "  1. 🎯 Per-patch cosine similarity (for each of 256/257 patches)"
echo "  2. 📊 Per-image cosine similarity (average of all patches per image)"
echo "  3. 🌐 Global cosine similarity (average across all images)"
echo "  4. 📈 Quality distribution analysis"
echo "  5. 📋 Comprehensive JSON reporting"
echo ""
echo "Expected processing time: 30-60 minutes on CPU"
echo "Progress will be logged every 5 batches."
echo ""

# Start timer
EVAL_START_TIME=$(date +%s)

# Launch CPU-optimized evaluation
echo "▶️  Launching evaluation at $(date)..."
python eval_blip3o_patch_similarity_cpu.py.py \
    --model_path "$MODEL_PATH" \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --training_mode "$TRAINING_MODE" \
    --num_samples $NUM_SAMPLES \
    --batch_size $BATCH_SIZE \
    --num_inference_steps $NUM_INFERENCE_STEPS \
    --max_eval_shards 1 \
    --cpu_threads $CPU_THREADS \
    --memory_efficient \
    --progress_frequency 5 \
    --same_data_eval \
    --normalize_embeddings \
    --save_detailed_results \
    --device cpu \
    --torch_dtype float32

EXIT_CODE=$?
EVAL_END_TIME=$(date +%s)
EVAL_DURATION=$((EVAL_END_TIME - EVAL_START_TIME))

# Results analysis
echo ""
echo "========================================================================"
echo "📊 CPU-OPTIMIZED BLIP3-O EVALUATION RESULTS"
echo "========================================================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $(hostname)"
echo "Evaluation Type: CPU-Optimized Cosine Similarity Analysis"
echo "Evaluation Duration: $EVAL_DURATION seconds ($((EVAL_DURATION/60)) minutes)"
echo "Total Runtime: $SECONDS seconds"
echo "Date: $(date)"

if [ $EXIT_CODE -eq 0 ]; then
    echo "Status: ✅ SUCCESS - CPU EVALUATION COMPLETED"
    
    # Find and display results
    RESULTS_FILES=("$OUTPUT_DIR"/*results*.json)
    
    echo ""
    echo "📊 CPU EVALUATION RESULTS SUMMARY:"
    echo "================================="
    
    # Parse and display results
    if [ ${#RESULTS_FILES[@]} -gt 0 ] && [ -f "${RESULTS_FILES[0]}" ]; then
        echo "📋 Results File: ${RESULTS_FILES[0]}"
        
        # Extract key metrics using python
        python -c "
import json
import sys

try:
    with open('${RESULTS_FILES[0]}', 'r') as f:
        data = json.load(f)
    
    if 'results_summary' in data:
        results = data['results_summary']
        print()
        print(f'🎯 COSINE SIMILARITY RESULTS:')
        print(f'   Overall cosine similarity:    {results.get(\"overall_cosine_similarity\", 0):.4f}')
        print(f'   Per-image mean similarity:    {results.get(\"per_image_mean_similarity\", 0):.4f}')
        print(f'   High quality images (>0.7):  {results.get(\"high_quality_images_percentage\", 0):.1f}%')
        print(f'   Total images evaluated:       {results.get(\"total_images\", 0):,}')
        print(f'   Total patches evaluated:      {results.get(\"total_patches\", 0):,}')
        print()
        
        # CPU performance assessment
        overall_sim = results.get('overall_cosine_similarity', 0)
        if overall_sim > 0.8:
            print(f'🎉 EXCELLENT: Outstanding patch-level alignment on CPU!')
            print(f'🚀 Model shows excellent overfitting - CPU evaluation successful')
        elif overall_sim > 0.6:
            print(f'✅ VERY GOOD: Strong patch-level performance on CPU')
            print(f'🎯 Model successfully learned patch-level mapping')
        elif overall_sim > 0.4:
            print(f'🔄 GOOD: Solid patch-level learning detected')
            print(f'💡 Model shows promise, CPU evaluation completed')
        else:
            print(f'⚠️  NEEDS IMPROVEMENT: Low patch-level similarity')
            print(f'💡 Consider longer training or hyperparameter tuning')
    
    if 'cpu_configuration' in data:
        cpu_config = data['cpu_configuration']
        print()
        print(f'💻 CPU CONFIGURATION USED:')
        print(f'   CPU threads:         {cpu_config.get(\"cpu_threads\", \"unknown\")}')
        print(f'   Memory efficient:    {cpu_config.get(\"memory_efficient\", \"unknown\")}')
        print(f'   Batch size:          {cpu_config.get(\"batch_size\", \"unknown\")}')
        print(f'   Inference steps:     {cpu_config.get(\"inference_steps\", \"unknown\")}')
    
    print()
    print(f'💾 Detailed results saved to: $OUTPUT_DIR')

except Exception as e:
    print(f'❌ Could not parse results: {e}')
    sys.exit(1)
"
    else
        echo "⚠️  No results file found, but evaluation may have completed"
    fi
    
    # Show output directory contents
    echo ""
    echo "📁 Generated Files:"
    echo "=================="
    ls -la "$OUTPUT_DIR"
    
    echo ""
    echo "✅ CPU EVALUATION COMPLETED SUCCESSFULLY"
    echo ""
    echo "📋 What was evaluated on CPU:"
    echo "   ✅ Per-patch cosine similarity for each patch in each image"
    echo "   ✅ Per-image average cosine similarity (mean of all patches)"
    echo "   ✅ Global average cosine similarity (mean across all images)"
    echo "   ✅ Quality distribution analysis and thresholds"
    echo "   ✅ Comprehensive JSON reporting for further analysis"
    echo ""
    echo "🎯 CPU Evaluation Benefits:"
    echo "   • No GPU dependencies - works on any CPU node"
    echo "   • Memory efficient processing for large datasets"
    echo "   • Reliable evaluation using pre-computed embeddings"
    echo "   • Detailed performance metrics and quality analysis"
    echo ""
    echo "📊 Next Steps:"
    echo "   • Review the comprehensive results in: $OUTPUT_DIR"
    echo "   • Analyze the quality distribution and similarity scores"
    echo "   • Use results to assess model overfitting performance"
    echo "   • Compare with training metrics if available"
    
else
    echo "Status: ❌ FAILED"
    echo ""
    echo "❌ CPU EVALUATION FAILED WITH EXIT CODE: $EXIT_CODE"
    echo ""
    echo "🔍 CPU Troubleshooting:"
    echo "   1. Check that model path is correct and accessible"
    echo "   2. Verify embeddings directory and manifest file exist"
    echo "   3. Ensure sufficient CPU memory is available"
    echo "   4. Try reducing --batch_size to 2 for lower memory usage"
    echo "   5. Try reducing --num_samples for faster testing"
    echo "   6. Check Python environment and dependencies"
    echo "   7. Verify model and embeddings compatibility"
    echo ""
    echo "📂 Log files:"
    echo "   Output: ./slurm_out/blip3o_cpu_eval_${SLURM_JOB_ID}.out"
    echo "   Error:  ./slurm_out/blip3o_cpu_eval_${SLURM_JOB_ID}.err"
    echo ""
    echo "🔧 Quick fixes to try:"
    echo "   • Reduce batch size: add --batch_size 2 to the command"
    echo "   • Reduce samples: add --num_samples 100 for quick test"
    echo "   • Check paths: verify MODEL_PATH and EMBEDDINGS_DIR"
    echo "   • Memory: request more memory with #SBATCH --mem=128G"
fi

echo ""
echo "========================================================================"
echo "🏁 CPU EVALUATION SUMMARY"
echo "========================================================================"

# Resource usage summary
echo "📊 Resource Usage:"
echo "   Job ID: $SLURM_JOB_ID"
echo "   Node: $(hostname)"
echo "   CPUs allocated: $SLURM_CPUS_PER_TASK"
echo "   Memory allocated: $SLURM_MEM_PER_NODE MB"
echo "   CPU evaluation time: $EVAL_DURATION seconds ($((EVAL_DURATION/60)) minutes)"
echo "   Total job time: $SECONDS seconds ($((SECONDS/60)) minutes)"

# Final status
if [ $EXIT_CODE -eq 0 ]; then
    echo ""
    echo "🎉 SUCCESS: CPU evaluation completed successfully!"
    echo ""
    echo "📋 Accomplished on CPU:"
    echo "   ✅ Comprehensive cosine similarity analysis without GPU"
    echo "   ✅ Per-patch, per-image, and global similarity computation"
    echo "   ✅ Memory-efficient processing optimized for CPU"
    echo "   ✅ Detailed JSON reporting and quality analysis"
    echo "   ✅ Reliable evaluation using pre-computed embeddings"
    echo ""
    echo "🎯 Key Benefits of CPU Evaluation:"
    echo "   • No GPU queue waiting time"
    echo "   • Reliable and reproducible results"
    echo "   • Cost-effective for evaluation tasks"
    echo "   • Works with any CPU allocation on Snellius"
else
    echo ""
    echo "❌ FAILURE: CPU evaluation encountered issues"
    echo ""
    echo "💡 Recommendations:"
    echo "   • Check the error logs above for specific issues"
    echo "   • Verify all paths are accessible from compute node"
    echo "   • Try with smaller batch size and sample count"
    echo "   • Ensure embeddings are compatible with model"
    echo "   • Contact support if paths are correct but evaluation fails"
fi

echo "========================================================================"

echo "🏁 CPU evaluation job completed at $(date)"

exit $EXIT_CODE