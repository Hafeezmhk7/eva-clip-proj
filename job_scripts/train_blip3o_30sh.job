#!/bin/bash
#SBATCH --job-name=blip3o_ddp
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=3
#SBATCH --ntasks=3
#SBATCH --ntasks-per-node=3
#SBATCH --cpus-per-task=12
#SBATCH --time=6:00:00
#SBATCH --mem=160G
#SBATCH --output=./slurm_out/blip3o_ddp_%j.out
#SBATCH --error=./slurm_out/blip3o_ddp_%j.err

# =============================================================================
# BLIP3-o Multi-GPU DDP Training - InfiniBand Configuration
# =============================================================================

echo "ðŸš€ BLIP3-o Multi-GPU DDP Training with InfiniBand"
echo "=================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPUs: ${SLURM_GPUS_ON_NODE}"
echo "Tasks: ${SLURM_NTASKS}"
echo "=================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# =============================================================================
# CRITICAL: NCCL Configuration for InfiniBand
# =============================================================================

# Master node setup
export MASTER_ADDR=$(scontrol show hostname ${SLURM_NODELIST} | head -n 1)
export MASTER_PORT=${MASTER_PORT:-29500}
export WORLD_SIZE=${SLURM_NTASKS}

# NCCL InfiniBand Configuration (CRITICAL!)
export NCCL_SOCKET_IFNAME=ib0
export NCCL_IB_DISABLE=0
export NCCL_DEBUG=INFO
export NCCL_DEBUG_SUBSYS=ALL
export NCCL_IB_HCA=mlx5_4
export NCCL_NET_GDR_LEVEL=2
export NCCL_P2P_LEVEL=NVL

echo "Network Configuration:"
echo "  Using InfiniBand: ib0 (172.22.63.191)"
echo "  Master: $MASTER_ADDR:$MASTER_PORT"
echo "  World size: $WORLD_SIZE"
echo "  NCCL_SOCKET_IFNAME: $NCCL_SOCKET_IFNAME"

# PyTorch memory settings
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512,garbage_collection_threshold:0.6"
export CUDA_LAUNCH_BLOCKING=0
export TORCH_SHOW_CPP_STACKTRACES=1

# Threading
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}
export MKL_NUM_THREADS=${SLURM_CPUS_PER_TASK}

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================

EMBEDDINGS_DIR="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/patch_only_256_tokens"
OUTPUT_DIR="./checkpoints_ddp_$(date +%Y%m%d_%H%M%S)"
TASK_MODE="clip_denoising"

# Model configuration
MODEL_SIZE="base"
TRAINING_MODE="patch_only"
PREDICTION_TYPE="velocity"

# Training hyperparameters
LEARNING_RATE=1e-4
BATCH_SIZE=2
GRADIENT_ACCUMULATION_STEPS=8
NUM_EPOCHS=5
WARMUP_STEPS=100
WEIGHT_DECAY=0.01
MAX_GRAD_NORM=1.0

# Memory optimization
MAX_SHARD_CACHE=2
SAMPLES_PER_SHARD_LOAD=500
MAX_SHARDS=35

# Create directories
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

# =============================================================================
# VERIFY NETWORK BEFORE TRAINING
# =============================================================================

echo ""
echo "Verifying network configuration..."
ip addr show ib0 | grep inet
ibstat | grep State | head -2

# =============================================================================
# LAUNCH TRAINING
# =============================================================================

echo ""
echo "ðŸš€ Launching Multi-GPU DDP Training..."
echo "======================================"

srun python train_eva_repro_ddp.py \
    --task_mode "$TASK_MODE" \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --model_size "$MODEL_SIZE" \
    --training_mode "$TRAINING_MODE" \
    --prediction_type "$PREDICTION_TYPE" \
    --learning_rate $LEARNING_RATE \
    --batch_size $BATCH_SIZE \
    --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
    --num_epochs $NUM_EPOCHS \
    --warmup_steps $WARMUP_STEPS \
    --weight_decay $WEIGHT_DECAY \
    --max_grad_norm $MAX_GRAD_NORM \
    --max_shard_cache $MAX_SHARD_CACHE \
    --samples_per_shard_load $SAMPLES_PER_SHARD_LOAD \
    --max_shards $MAX_SHARDS \
    --sphere_constraint_weight 0.1 \
    --noise_schedule uniform \
    --max_noise_level 0.9 \
    --min_noise_level 0.1 \
    --eval_every_n_steps 250 \
    --eval_num_samples 300 \
    --eval_inference_steps 25 \
    --num_workers 2 \
    --fp16

TRAINING_EXIT_CODE=$?

echo ""
echo "Training completed with exit code: $TRAINING_EXIT_CODE"
echo "======================================"

exit $TRAINING_EXIT_CODE