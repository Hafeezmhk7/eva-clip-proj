#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --job-name=blip3o_extract_chunked
#SBATCH --time=24:00:00
#SBATCH --output=./slurm_out/extract_chunked_%j.out
#SBATCH --error=./slurm_out/extract_chunked_%j.err
#SBATCH --mem=64GB
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1

echo "üöÄ Starting BLIP3-o CHUNKED Embedding Extraction - 256 TOKENS"
echo "============================================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURMD_NODENAME" 
echo "Date: $(date)"
echo "Working directory: $(pwd)"
echo "User: $(whoami)"
echo "CUDA Visible Devices: $CUDA_VISIBLE_DEVICES"
echo ""
echo "üéØ CHUNKED EXTRACTION APPROACH:"
echo "   ‚Ä¢ Uses structured temp manager"
echo "   ‚Ä¢ Persistent storage for embeddings (14-day retention)"
echo "   ‚Ä¢ Automatic cache management"
echo "   ‚Ä¢ Sequential processing of TAR files"

# =============================================================================
# TEMP MANAGER SETUP
# =============================================================================

echo ""
echo "üóÇÔ∏è STEP 0: Setting up structured temp environment..."
echo "==================================================="

# Load modules
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

# Activate conda environment
source activate eva_clip_env

# Run Python to initialize temp manager
python -c "
import sys
sys.path.insert(0, 'src/modules/utils')
from temp_manager import setup_snellius_environment
manager = setup_snellius_environment('blip3o_workspace')
manager.setup_model_cache()
print(f'‚úÖ Temp manager initialized:')
print(f'   Persistent workspace: {manager.persistent_workspace}')
print(f'   Job temp: {manager.job_temp}')
print(f'   Embeddings dir: {manager.get_embeddings_dir()}')
print(f'   Datasets dir: {manager.get_datasets_dir()}')
"

echo "‚úÖ Environment setup completed"

# =============================================================================
# STEP 1: DOWNLOAD TAR FILES
# =============================================================================

echo ""
echo "üì• STEP 1: Downloading dataset shards (30 shards for ~100k samples)..."
echo "======================================================================"

# Download 30 shards using temp manager
python src/data_hand/download_data.py --shards $(seq -s ' ' 0 29)

DOWNLOAD_EXIT_CODE=$?

if [ $DOWNLOAD_EXIT_CODE -ne 0 ]; then
    echo "‚ùå Download failed with exit code: $DOWNLOAD_EXIT_CODE"
    echo "Trying with fewer shards..."
    
    # Fallback: try with 20 shards
    python src/data_hand/download_data.py --shards $(seq -s ' ' 0 19)
    
    DOWNLOAD_EXIT_CODE=$?
    if [ $DOWNLOAD_EXIT_CODE -ne 0 ]; then
        echo "‚ùå Even reduced download failed. Exiting."
        exit 1
    fi
fi

echo "‚úÖ Dataset download completed"

# =============================================================================
# STEP 2: CHUNKED EMBEDDING EXTRACTION
# =============================================================================

echo ""
echo "üß† STEP 2: Chunked embedding extraction..."
echo "=========================================="

# Run chunked embedding extraction
python src/modules/extract_embeddings_g.py

EXTRACTION_EXIT_CODE=$?

if [ $EXTRACTION_EXIT_CODE -ne 0 ]; then
    echo "‚ùå Chunked embedding extraction failed with exit code: $EXTRACTION_EXIT_CODE"
    exit 1
fi

echo "‚úÖ Chunked embedding extraction completed successfully!"

# =============================================================================
# STEP 3: VALIDATE EMBEDDINGS
# =============================================================================

echo ""
echo "üß™ STEP 3: Validating embeddings..."
echo "==================================="

# Get embeddings directory
EMBEDDINGS_DIR=$(python -c "import sys; sys.path.insert(0, 'src/utils'); from temp_manager import setup_snellius_environment; print(setup_snellius_environment('blip3o_workspace').get_embeddings_dir() / 'chunked_256_tokens')")

if [ ! -d "$EMBEDDINGS_DIR" ]; then
    echo "‚ùå Embeddings directory not found: $EMBEDDINGS_DIR"
    exit 1
fi

echo "‚úÖ Found embeddings directory: $EMBEDDINGS_DIR"

# Check for manifest file
MANIFEST_FILE="$EMBEDDINGS_DIR/embeddings_manifest.json"
if [ ! -f "$MANIFEST_FILE" ]; then
    echo "‚ùå Manifest file not found: $MANIFEST_FILE"
    exit 1
fi

echo "‚úÖ Found manifest file: $MANIFEST_FILE"

# Count shard files
SHARD_COUNT=$(find "$EMBEDDINGS_DIR" -name "embeddings_shard_*.pkl" | wc -l)
echo "üìä Found $SHARD_COUNT embedding shard files"

# Show total size
TOTAL_SIZE=$(du -sh "$EMBEDDINGS_DIR" | cut -f1)
echo "üìä Total embeddings size: $TOTAL_SIZE"

# Validate manifest
python -c "
import json
import sys

try:
    with open('$MANIFEST_FILE', 'r') as f:
        manifest = json.load(f)
    
    print(f'‚úÖ Manifest validation:')
    print(f'   Total shards: {manifest[\"total_shards\"]}')
    print(f'   Total samples: {manifest[\"total_samples\"]:,}')
    print(f'   Total size: {manifest[\"total_size_mb\"]:.1f} MB')
    print(f'   Format: {manifest[\"format_version\"]}')
    
    if manifest['total_samples'] >= 50000:
        print(f'‚úÖ Excellent! Over 50k samples for robust training')
    elif manifest['total_samples'] >= 20000:
        print(f'‚úÖ Good! Over 20k samples for decent training')
    else:
        print(f'‚ö†Ô∏è  Warning: Only {manifest[\"total_samples\"]} samples - consider more shards')
    
except Exception as e:
    print(f'‚ùå Manifest validation failed: {e}')
    sys.exit(1)
"

VALIDATION_EXIT_CODE=$?

if [ $VALIDATION_EXIT_CODE -ne 0 ]; then
    echo "‚ùå Manifest validation failed!"
    exit 1
fi

echo "‚úÖ Embeddings validation passed!"

# =============================================================================
# FINAL STEPS
# =============================================================================

echo ""
echo "üéâ CHUNKED EXTRACTION COMPLETED SUCCESSFULLY!"
echo "=============================================="
echo ""
echo "üìÅ EMBEDDINGS LOCATION:"
echo "   $EMBEDDINGS_DIR"
echo ""
echo "üîç WHAT'S NEXT:"
echo "   1. Start training: sbatch job_scripts/train_flow_match_256.job"
echo "   2. Use --auto_find_embeddings in training script"
echo ""
echo "üìã STORAGE INFO:"
echo "   ‚Ä¢ Embeddings stored in persistent workspace"
echo "   ‚Ä¢ 14-day automatic retention"
echo "   ‚Ä¢ Accessible across different jobs"
echo ""
echo "‚è±Ô∏è  Job completed at: $(date)"