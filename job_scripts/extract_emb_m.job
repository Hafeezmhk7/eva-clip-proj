#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=2
#SBATCH --job-name=blip3o_multi_gpu
#SBATCH --time=04:00:00
#SBATCH --output=./slurm_out/multi_gpu_%j.out
#SBATCH --error=./slurm_out/multi_gpu_%j.err
#SBATCH --mem=64GB
#SBATCH --cpus-per-task=16

echo "üöÄ Starting Multi-GPU BLIP3-o Embedding Extraction"
echo "================================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Date: $(date)"
echo "GPUs requested: 2"
echo "CUDA Visible Devices: $CUDA_VISIBLE_DEVICES"

# Create directories
mkdir -p slurm_out embeddings

# Load modules
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

# Activate environment
source activate eva_clip_env

# Show GPU information
echo "üéÆ GPU Configuration:"
nvidia-smi --query-gpu=index,name,memory.total --format=csv,noheader,nounits
echo ""

# Check total GPU memory
total_memory=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | awk '{sum+=$1} END {print sum}')
echo "üíæ Total GPU Memory: $total_memory MB"

# Memory optimizations for multi-GPU
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Check disk space
echo "üìä Disk Space Check:"
df -h . | head -2
echo ""

# Calculate effective batch size
echo "üìä Multi-GPU Configuration:"
echo "   GPUs: 2"
echo "   Batch size per GPU: 4"
echo "   Total effective batch size: 8"
echo "   Expected speedup: ~2x faster processing"
echo ""

# Run multi-GPU extraction
echo "üß† Starting multi-GPU extraction..."
python src/modules/extract_embeddings_g_m.py

# Check result
EXTRACTION_EXIT_CODE=$?

if [ $EXTRACTION_EXIT_CODE -eq 0 ]; then
    echo ""
    echo "‚úÖ Multi-GPU extraction completed successfully!"
    
    if [ -f "embeddings/blip3o_grid_embeddings.pkl" ]; then
        echo "üìÅ Final file created:"
        ls -lh embeddings/blip3o_grid_embeddings.pkl
        
        # Verify file
        echo "üß™ Verifying multi-GPU extraction results..."
        python -c "
import pickle
try:
    with open('embeddings/blip3o_grid_embeddings.pkl', 'rb') as f:
        data = pickle.load(f)
    config = data.get('config', {})
    print(f'‚úÖ File loads successfully with {data[\"total_samples\"]} samples')
    print(f'üìê CLIP shape: {data[\"clip_blip3o_embeddings\"].shape}')
    print(f'üìê EVA shape: {data[\"eva_blip3o_embeddings\"].shape}')
    print(f'üéÆ GPUs used: {config.get(\"num_gpus_used\", \"unknown\")}')
    print(f'üìè Batch size per GPU: {config.get(\"batch_size_per_gpu\", \"unknown\")}')
except Exception as e:
    print(f'‚ùå Verification failed: {e}')
"
        
        # Clean up multi-GPU checkpoint
        if [ -f "embeddings/extraction_checkpoint_multi_gpu.pkl" ]; then
            echo "üóëÔ∏è  Cleaning up multi-GPU checkpoint..."
            rm embeddings/extraction_checkpoint_multi_gpu.pkl
        fi
    fi
    
else
    echo "‚ùå Multi-GPU extraction failed!"
    echo "üîç Check for common issues:"
    
    # Check if both GPUs are available
    gpu_count=$(nvidia-smi --list-gpus | wc -l)
    echo "   Available GPUs: $gpu_count"
    
    # Check memory usage
    echo "   GPU Memory Usage:"
    nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits
    
    # Check for checkpoint
    if [ -f "embeddings/extraction_checkpoint_multi_gpu.pkl" ]; then
        echo "   Multi-GPU checkpoint exists - can resume"
    fi
fi

echo ""
echo "üéâ Multi-GPU job completed at: $(date)"
echo "‚è±Ô∏è Total runtime: $SECONDS seconds"

# Performance summary
if [ $EXTRACTION_EXIT_CODE -eq 0 ]; then
    echo ""
    echo "üèÅ Performance Summary:"
    echo "   Configuration: 2 GPUs, batch_size=8 (4 per GPU)"
    echo "   Theoretical speedup vs single GPU: ~2x"
    echo "   Memory usage: Distributed across 2 GPUs"
fi