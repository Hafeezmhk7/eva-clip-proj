#!/bin/bash
#SBATCH --job-name=blip3o_evaluation_optimized
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --cpus-per-gpu=18
#SBATCH --time=8:00:00  # INCREASED: Double the time limit
#SBATCH --mem=0
#SBATCH --output=./slurm_out/evaluation_%j.out
#SBATCH --error=./slurm_out/evaluation_%j.err

echo "🔍 BLIP3-o DiT Model Evaluation - OPTIMIZED VERSION"
echo "=================================================="
echo "🚀 OPTIMIZATIONS:"
echo "  • Increased time limit to 8 hours"
echo "  • Reduced sample size for faster evaluation"
echo "  • Larger batch sizes to improve efficiency"
echo "  • Optional checkpointing between tasks"
echo "=================================================="

# =============================================================================
# OPTIMIZATION OPTIONS
# =============================================================================

# OPTIMIZATION 1: Reduce sample size for faster evaluation
EVAL_MAX_SAMPLES=1000  # Reduced from 5000 to 1000 for faster eval
BATCH_SIZE=32          # Increased batch size for better GPU utilization

# OPTIMIZATION 2: Enable checkpointing (resume if previous task completed)
ENABLE_CHECKPOINTING=true
CHECKPOINT_DIR="${BLIP3O_WORKSPACE}/evaluation_checkpoints"

# OPTIMIZATION 3: Conditional task execution
RUN_TASK_1=true   # Set to false if Task 1 already completed
RUN_TASK_2=true   # Set to false if Task 2 already completed

echo "🎯 Evaluation Configuration (OPTIMIZED):"
echo "   Max samples: $EVAL_MAX_SAMPLES (reduced for speed)"
echo "   Batch size: $BATCH_SIZE (increased for efficiency)"
echo "   Checkpointing: $ENABLE_CHECKPOINTING"
echo "   Run Task 1: $RUN_TASK_1"
echo "   Run Task 2: $RUN_TASK_2"

# =============================================================================
# ENVIRONMENT SETUP (Same as before)
# =============================================================================

echo ""
echo "🔧 Environment Setup..."
echo "======================="

# Load modules
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

# Activate conda environment
source activate eva_clip_env

# Setup directories
export BLIP3O_USER=$(whoami)
export BLIP3O_JOB_ID=${SLURM_JOB_ID}
export BLIP3O_WORKSPACE="/scratch-shared/${BLIP3O_USER}/blip3o_workspace"
export BLIP3O_CHECKPOINTS="${BLIP3O_WORKSPACE}/checkpoints"
export BLIP3O_JOB_TEMP="/scratch-local/${BLIP3O_USER}.${BLIP3O_JOB_ID}/blip3o_eval_${BLIP3O_JOB_ID}"

# Create directories
mkdir -p "${BLIP3O_JOB_TEMP}"/{cache,results}
mkdir -p "$CHECKPOINT_DIR"

# Redirect model caches
export TORCH_HOME="${BLIP3O_JOB_TEMP}/cache/torch"
export HF_HOME="${BLIP3O_JOB_TEMP}/cache/huggingface"
export TRANSFORMERS_CACHE="${BLIP3O_JOB_TEMP}/cache/transformers"
mkdir -p "${TORCH_HOME}" "${HF_HOME}" "${TRANSFORMERS_CACHE}"

# =============================================================================
# MODEL AND DATA PATHS
# =============================================================================

echo ""
echo "📍 Setting up paths..."
echo "======================"

MODEL_PATH="/scratch-shared/scur2711/blip3o_workspace/checkpoints/blip3o_multi_gpu_fixed_cosine_13170504_20250716_034251"
COCO_ROOT="./data/coco"
RESULTS_DIR="${BLIP3O_JOB_TEMP}/results"
PERSISTENT_RESULTS_DIR="${BLIP3O_WORKSPACE}/evaluation_results/eval_optimized_${BLIP3O_JOB_ID}_$(date +%Y%m%d_%H%M%S)"

mkdir -p "$RESULTS_DIR" "$PERSISTENT_RESULTS_DIR"

# Verify paths
if [ ! -d "$MODEL_PATH" ]; then
    echo "❌ Model not found: $MODEL_PATH"
    exit 1
fi

if [ ! -d "$COCO_ROOT" ]; then
    echo "❌ COCO dataset not found: $COCO_ROOT"
    exit 1
fi

echo "✅ Model: $MODEL_PATH"
echo "✅ COCO: $COCO_ROOT"
echo "✅ Results: $PERSISTENT_RESULTS_DIR"

# =============================================================================
# CHECKPOINTING FUNCTIONS
# =============================================================================

check_task_completed() {
    local task_name=$1
    local checkpoint_file="$CHECKPOINT_DIR/${task_name}_completed_${BLIP3O_JOB_ID}.flag"
    [ -f "$checkpoint_file" ]
}

mark_task_completed() {
    local task_name=$1
    local checkpoint_file="$CHECKPOINT_DIR/${task_name}_completed_${BLIP3O_JOB_ID}.flag"
    echo "$(date): Task $task_name completed" > "$checkpoint_file"
    echo "✅ Marked $task_name as completed"
}

# =============================================================================
# TASK 1: ALIGNMENT EVALUATION (OPTIMIZED)
# =============================================================================

# if [ "$RUN_TASK_1" = "true" ]; then
#     if [ "$ENABLE_CHECKPOINTING" = "true" ] && check_task_completed "alignment"; then
#         echo ""
#         echo "⏭️  Task 1 (Alignment) already completed, skipping..."
#     else
#         echo ""
#         echo "📊 Starting Task 1: Alignment Evaluation (OPTIMIZED)"
#         echo "====================================================="
#         echo "🚀 OPTIMIZATIONS APPLIED:"
#         echo "   • Sample size: $EVAL_MAX_SAMPLES (reduced for speed)"
#         echo "   • Batch size: $BATCH_SIZE (increased for efficiency)"
#         echo "   • Fair comparison in CLIP's aligned space"

#         ALIGNMENT_START_TIME=$(date +%s)

#         python evaluate_alignment.py \
#             --blip3o_model_path "$MODEL_PATH" \
#             --coco_root "$COCO_ROOT" \
#             --max_samples $EVAL_MAX_SAMPLES \
#             --batch_size $BATCH_SIZE \
#             --device cuda \
#             --results_dir "${RESULTS_DIR}/alignment" \
#             --save_detailed \
#             --verbose

#         ALIGNMENT_EXIT_CODE=$?
#         ALIGNMENT_END_TIME=$(date +%s)
#         ALIGNMENT_DURATION=$((ALIGNMENT_END_TIME - ALIGNMENT_START_TIME))

#         if [ $ALIGNMENT_EXIT_CODE -eq 0 ]; then
#             echo "✅ Task 1 completed successfully in ${ALIGNMENT_DURATION}s"
#             if [ "$ENABLE_CHECKPOINTING" = "true" ]; then
#                 mark_task_completed "alignment"
#             fi
#         else
#             echo "❌ Task 1 failed with exit code: $ALIGNMENT_EXIT_CODE"
#         fi
#     fi
# else
#     echo "⏭️  Skipping Task 1 (alignment) as requested"
#     ALIGNMENT_EXIT_CODE=0
# fi

# =============================================================================
# TASK 2: RECALL EVALUATION (OPTIMIZED)
# =============================================================================

if [ "$RUN_TASK_2" = "true" ]; then
    if [ "$ENABLE_CHECKPOINTING" = "true" ] && check_task_completed "recall"; then
        echo ""
        echo "⏭️  Task 2 (Recall) already completed, skipping..."
    else
        echo ""
        echo "🎯 Starting Task 2: Recall Evaluation (OPTIMIZED)"
        echo "================================================="
        echo "🚀 OPTIMIZATIONS APPLIED:"
        echo "   • Sample size: $EVAL_MAX_SAMPLES (reduced for speed)"
        echo "   • Batch size: $BATCH_SIZE (increased for efficiency)"
        echo "   • Fair comparison in CLIP's aligned space"

        RECALL_START_TIME=$(date +%s)

        python evaluate_recall.py \
            --blip3o_model_path "$MODEL_PATH" \
            --coco_root "$COCO_ROOT" \
            --max_samples $EVAL_MAX_SAMPLES \
            --batch_size $BATCH_SIZE \
            --k_values 1 5 10 \
            --device cuda \
            --results_dir "${RESULTS_DIR}/recall" \
            --save_detailed \
            --verbose

        RECALL_EXIT_CODE=$?
        RECALL_END_TIME=$(date +%s)
        RECALL_DURATION=$((RECALL_END_TIME - RECALL_START_TIME))

        if [ $RECALL_EXIT_CODE -eq 0 ]; then
            echo "✅ Task 2 completed successfully in ${RECALL_DURATION}s"
            if [ "$ENABLE_CHECKPOINTING" = "true" ]; then
                mark_task_completed "recall"
            fi
        else
            echo "❌ Task 2 failed with exit code: $RECALL_EXIT_CODE"
        fi
    fi
else
    echo "⏭️  Skipping Task 2 (recall) as requested"
    RECALL_EXIT_CODE=0
fi

# =============================================================================
# RESULTS ARCHIVING
# =============================================================================

echo ""
echo "📁 Archiving Results..."
echo "======================"

if [ -d "$RESULTS_DIR" ] && [ "$(ls -A "$RESULTS_DIR")" ]; then
    cp -r "$RESULTS_DIR"/* "$PERSISTENT_RESULTS_DIR/"
    
    # Create enhanced summary
    SUMMARY_FILE="$PERSISTENT_RESULTS_DIR/evaluation_summary_optimized.txt"
    
    cat > "$SUMMARY_FILE" << EOF
BLIP3-o DiT Evaluation Summary - OPTIMIZED VERSION
==================================================
Job ID: $SLURM_JOB_ID
Date: $(date)
Node: $SLURMD_NODENAME

🚀 OPTIMIZATIONS APPLIED:
- Reduced sample size: $EVAL_MAX_SAMPLES (from 5000)
- Increased batch size: $BATCH_SIZE (from 16)
- Extended time limit: 8 hours (from 4)
- Checkpointing enabled: $ENABLE_CHECKPOINTING
- Fair comparison in CLIP-aligned 768-dim space

Model Information:
- Path: $MODEL_PATH
- COCO samples evaluated: $EVAL_MAX_SAMPLES
- Embedding space: CLIP-aligned 768-dimensional
- Uses visual projection: YES

Task Results:
- Task 1 (Alignment): $([ $ALIGNMENT_EXIT_CODE -eq 0 ] && echo "SUCCESS" || echo "FAILED")
- Task 2 (Recall): $([ $RECALL_EXIT_CODE -eq 0 ] && echo "SUCCESS" || echo "FAILED")

Performance Improvements:
- Faster evaluation through reduced sample size
- Better GPU utilization with larger batches
- Checkpoint system prevents re-running completed tasks
- Extended time limit ensures completion

Results Location: $PERSISTENT_RESULTS_DIR
EOF

    echo "✅ Results archived to: $PERSISTENT_RESULTS_DIR"
    echo "📄 Summary: $SUMMARY_FILE"
    
    # Show quick results if available
    if [ -f "$PERSISTENT_RESULTS_DIR/alignment/alignment_summary.json" ]; then
        echo ""
        echo "📊 Quick Alignment Results (OPTIMIZED - $EVAL_MAX_SAMPLES samples):"
        python -c "
import json
try:
    with open('$PERSISTENT_RESULTS_DIR/alignment/alignment_summary.json', 'r') as f:
        data = json.load(f)
    print(f'  CLIP Vision (768-dim):     {data.get(\"clip_text_clip_vision_mean\", 0):.4f}')
    print(f'  Generated CLIP (768-dim):  {data.get(\"clip_text_generated_mean\", 0):.4f}')
    print(f'  Difference:                {data.get(\"difference_mean\", 0):+.4f}')
    print(f'  Samples:                   {data.get(\"num_samples\", 0)}')
except: pass
"
    fi
    
    if [ -f "$PERSISTENT_RESULTS_DIR/recall/recall_summary.json" ]; then
        echo ""
        echo "🎯 Quick Recall Results (OPTIMIZED - $EVAL_MAX_SAMPLES samples):"
        python -c "
import json
try:
    with open('$PERSISTENT_RESULTS_DIR/recall/recall_summary.json', 'r') as f:
        data = json.load(f)
    for k in [1, 5, 10]:
        clip_recall = data.get(f'clip_vision_recall@{k}', 0)
        gen_recall = data.get(f'generated_recall@{k}', 0)
        diff = data.get(f'recall@{k}_difference', 0)
        print(f'  Recall@{k:2d} - CLIP: {clip_recall:.4f}, Generated: {gen_recall:.4f}, Diff: {diff:+.4f}')
except: pass
"
    fi
fi

# =============================================================================
# FINAL SUMMARY
# =============================================================================

echo ""
echo "🎉 OPTIMIZED EVALUATION COMPLETED!"
echo "=================================="

TOTAL_DURATION=$SECONDS
echo "📊 Final Summary:"
echo "   Task 1 (Alignment): $([ $ALIGNMENT_EXIT_CODE -eq 0 ] && echo "✅ SUCCESS" || echo "❌ FAILED")"
echo "   Task 2 (Recall): $([ $RECALL_EXIT_CODE -eq 0 ] && echo "✅ SUCCESS" || echo "❌ FAILED")"
echo "   Sample size: $EVAL_MAX_SAMPLES (optimized)"
echo "   Total runtime: $TOTAL_DURATION seconds"
echo "   Results: $PERSISTENT_RESULTS_DIR"

echo ""
echo "🚀 Optimization Benefits:"
echo "   • 5x faster evaluation (1K vs 5K samples)"
echo "   • Better GPU utilization (batch size $BATCH_SIZE)"
echo "   • Checkpoint system prevents work loss"
echo "   • Fair comparison methodology maintained"

if [ $ALIGNMENT_EXIT_CODE -eq 0 ] && [ $RECALL_EXIT_CODE -eq 0 ]; then
    echo ""
    echo "🚀 Both evaluations completed successfully with optimizations!"
    exit 0
else
    echo ""
    echo "⚠️  Some evaluations failed. Check logs for details."
    exit 1
fi