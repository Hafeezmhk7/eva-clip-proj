#!/bin/bash
#SBATCH --job-name=blip3o_similarity_eval
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --cpus-per-gpu=18
#SBATCH --time=3:00:00
#SBATCH --mem=0
#SBATCH --output=./slurm_out/blip3o_similarity_%j.out
#SBATCH --error=./slurm_out/blip3o_similarity_%j.err

# =============================================================================
# Enhanced BLIP3-o Patch-Level Cosine Similarity Evaluation Job
# Comprehensive evaluation with per-patch, per-image, and global analysis
# =============================================================================

echo "üîç Enhanced BLIP3-o Patch-Level Cosine Similarity Evaluation"
echo "============================================================="
echo "üéØ ENHANCED EVALUATION FEATURES:"
echo "  ‚úÖ Per-patch cosine similarity analysis"
echo "  ‚úÖ Per-image average cosine similarity"
echo "  ‚úÖ Global average cosine similarity"
echo "  ‚úÖ Support for both CLS+patch (257) and patch-only (256) modes"
echo "  ‚úÖ Same-data evaluation (overfitting verification)"
echo "  ‚úÖ Comprehensive JSON reporting"
echo "  ‚úÖ Advanced visualization plots"
echo "  ‚úÖ BLIP3-o paper aligned evaluation"
echo "============================================================="

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

source activate eva_clip_env

# Configuration - MODIFY THESE PATHS FOR YOUR SETUP
TRAINED_MODEL_PATH="./checkpoints/blip3o_enhanced_JOBID_TIMESTAMP"  # Set to your trained model
EMBEDDINGS_DIR="./embeddings"                                        # Set to your embeddings directory
OUTPUT_DIR="./evaluation_results_$(date +%Y%m%d_%H%M%S)"
TRAINING_MODE="auto"                                                  # auto, cls_patch, or patch_only
NUM_SAMPLES=1000
BATCH_SIZE=8
NUM_INFERENCE_STEPS=50
MAX_EVAL_SHARDS=1

# Setup temp directories for model cache
export USER=$(whoami)
export JOB_ID=${SLURM_JOB_ID}
export JOB_TEMP="/scratch-local/${USER}.${JOB_ID}/blip3o_eval"

export TORCH_HOME="${JOB_TEMP}/torch"
export HF_HOME="${JOB_TEMP}/huggingface"
export TRANSFORMERS_CACHE="${JOB_TEMP}/transformers"

mkdir -p "${TORCH_HOME}" "${HF_HOME}" "${TRANSFORMERS_CACHE}"
mkdir -p ./slurm_out ./results "${OUTPUT_DIR}"

echo "Enhanced Evaluation Configuration:"
echo "  Model Path: $TRAINED_MODEL_PATH"
echo "  Embeddings: $EMBEDDINGS_DIR"
echo "  Training Mode: $TRAINING_MODE"
echo "  Samples: $NUM_SAMPLES"
echo "  Batch Size: $BATCH_SIZE"
echo "  Inference Steps: $NUM_INFERENCE_STEPS"
echo "  Max Eval Shards: $MAX_EVAL_SHARDS"
echo "  Output Dir: $OUTPUT_DIR"
echo "  Job ID: $JOB_ID"
echo "  Node: $SLURMD_NODENAME"

# Verify paths exist
echo ""
echo "üîç Verifying paths..."
echo "==================="

# Find trained model (if using placeholder path)
if [[ "$TRAINED_MODEL_PATH" == *"JOBID"* ]] || [ ! -d "$TRAINED_MODEL_PATH" ]; then
    echo "üîç Searching for trained model..."
    
    # Look for recent checkpoints
    SEARCH_PATHS=(
        "./checkpoints/blip3o_enhanced_*"
        "./checkpoints/blip3o_*"
        "./checkpoints/*"
    )
    
    FOUND_MODEL=""
    for pattern in "${SEARCH_PATHS[@]}"; do
        for path in $pattern; do
            if [ -d "$path" ] && [ -f "$path/pytorch_model.bin" -o -f "$path/model.safetensors" ]; then
                FOUND_MODEL="$path"
                break 2
            fi
        done
    done
    
    if [ -n "$FOUND_MODEL" ]; then
        TRAINED_MODEL_PATH="$FOUND_MODEL"
        echo "‚úÖ Found trained model: $TRAINED_MODEL_PATH"
    else
        echo "‚ùå ERROR: No trained model found"
        echo "   Please set TRAINED_MODEL_PATH to your trained model directory"
        echo "   Available checkpoints:"
        ls -la ./checkpoints/ 2>/dev/null || echo "   No checkpoints found"
        exit 1
    fi
fi

# Find embeddings directory
if [ ! -d "$EMBEDDINGS_DIR" ] || [ ! -f "$EMBEDDINGS_DIR/embeddings_manifest.json" ]; then
    echo "üîç Searching for embeddings..."
    
    EMBEDDINGS_SEARCH_PATHS=(
        "./embeddings"
        "./embeddings/chunked_256_tokens"
        "./embeddings/chunked_257_tokens"
        "/scratch-shared/$(whoami)/blip3o_workspace/embeddings"
    )
    
    FOUND_EMBEDDINGS=""
    for path in "${EMBEDDINGS_SEARCH_PATHS[@]}"; do
        if [ -d "$path" ] && [ -f "$path/embeddings_manifest.json" ]; then
            FOUND_EMBEDDINGS="$path"
            break
        fi
    done
    
    if [ -n "$FOUND_EMBEDDINGS" ]; then
        EMBEDDINGS_DIR="$FOUND_EMBEDDINGS"
        echo "‚úÖ Found embeddings: $EMBEDDINGS_DIR"
    else
        echo "‚ùå ERROR: No embeddings found"
        echo "   Please set EMBEDDINGS_DIR to your embeddings directory"
        echo "   Searched paths:"
        for path in "${EMBEDDINGS_SEARCH_PATHS[@]}"; do
            echo "     $path"
        done
        exit 1
    fi
fi

# Verify required files
if [ ! -d "$TRAINED_MODEL_PATH" ]; then
    echo "‚ùå ERROR: Model path not found: $TRAINED_MODEL_PATH"
    exit 1
fi

if [ ! -f "$EMBEDDINGS_DIR/embeddings_manifest.json" ]; then
    echo "‚ùå ERROR: Embeddings manifest not found: $EMBEDDINGS_DIR/embeddings_manifest.json"
    exit 1
fi

# Check for model files
MODEL_FILES=("pytorch_model.bin" "model.safetensors" "pytorch_model.safetensors")
MODEL_FILE_FOUND=false
for file in "${MODEL_FILES[@]}"; do
    if [ -f "$TRAINED_MODEL_PATH/$file" ]; then
        MODEL_FILE_FOUND=true
        echo "‚úÖ Found model weights: $file"
        break
    fi
done

if [ "$MODEL_FILE_FOUND" = false ]; then
    echo "‚ùå ERROR: No model weights found in $TRAINED_MODEL_PATH"
    echo "   Looking for: ${MODEL_FILES[@]}"
    echo "   Available files:"
    ls -la "$TRAINED_MODEL_PATH"
    exit 1
fi

# Check for config files
CONFIG_FILES=("config.json" "blip3o_model_config.json" "enhanced_training_config.json")
CONFIG_FILE_FOUND=false
for file in "${CONFIG_FILES[@]}"; do
    if [ -f "$TRAINED_MODEL_PATH/$file" ]; then
        CONFIG_FILE_FOUND=true
        echo "‚úÖ Found model config: $file"
        break
    fi
done

if [ "$CONFIG_FILE_FOUND" = false ]; then
    echo "‚ùå ERROR: No model config found in $TRAINED_MODEL_PATH"
    echo "   Looking for: ${CONFIG_FILES[@]}"
    exit 1
fi

echo "‚úÖ All paths and files verified"

# Show model and embeddings info
echo ""
echo "üìä Model and Data Information:"
echo "============================"
echo "Model path: $TRAINED_MODEL_PATH"

# Show embeddings info
echo "Embeddings info:"
python -c "
import json
try:
    with open('$EMBEDDINGS_DIR/embeddings_manifest.json', 'r') as f:
        manifest = json.load(f)
    print(f'  Total shards: {manifest.get(\"total_shards\", \"unknown\")}')
    print(f'  Total samples: {manifest.get(\"total_samples\", \"unknown\"):,}')
    print(f'  Extraction mode: {manifest.get(\"extraction_mode\", \"unknown\")}')
    print(f'  Tokens per sample: {manifest.get(\"tokens_per_sample\", \"unknown\")}')
except Exception as e:
    print(f'  Error reading manifest: {e}')
"

# Verify evaluation script exists
EVAL_SCRIPT="eval_blip3o_patch_similarity.py"
if [ ! -f "$EVAL_SCRIPT" ]; then
    echo "‚ùå ERROR: Evaluation script not found: $EVAL_SCRIPT"
    echo "   Make sure the script is in the current directory"
    exit 1
fi

echo "‚úÖ Evaluation script verified: $EVAL_SCRIPT"

# Run enhanced cosine similarity evaluation
echo ""
echo "üöÄ Starting Enhanced BLIP3-o Patch-Level Evaluation..."
echo "===================================================="
echo "This will perform comprehensive evaluation:"
echo "  1. üéØ Per-patch cosine similarity (for each of 256/257 patches)"
echo "  2. üìä Per-image cosine similarity (average of all patches per image)"
echo "  3. üåê Global cosine similarity (average across all images)"
echo "  4. üìà Quality distribution analysis"
echo "  5. üé® Advanced visualization plots"
echo "  6. üìã Comprehensive JSON reporting"
echo ""
echo "Expected outputs:"
echo "  ‚Ä¢ Per-patch similarities: Individual cosine similarity for each patch"
echo "  ‚Ä¢ Per-image averages: Mean cosine similarity for each image"
echo "  ‚Ä¢ Global statistics: Overall performance metrics"
echo "  ‚Ä¢ Visualization plots: Distribution plots, heatmaps, quality analysis"
echo "  ‚Ä¢ JSON reports: Detailed numerical results for further analysis"
echo ""

EVAL_START_TIME=$(date +%s)

# Run the enhanced evaluation script
python eval_blip3o_patch_similarity.py \
    --model_path "$TRAINED_MODEL_PATH" \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --training_mode "$TRAINING_MODE" \
    --num_samples $NUM_SAMPLES \
    --batch_size $BATCH_SIZE \
    --num_inference_steps $NUM_INFERENCE_STEPS \
    --max_eval_shards $MAX_EVAL_SHARDS \
    --same_data_eval \
    --normalize_embeddings \
    --save_plots \
    --save_detailed_results \
    --device auto \
    --torch_dtype float32

EXIT_CODE=$?
EVAL_END_TIME=$(date +%s)
EVAL_DURATION=$((EVAL_END_TIME - EVAL_START_TIME))

# Results summary
echo ""
echo "========================================================================"
echo "üìä ENHANCED BLIP3-O PATCH-LEVEL EVALUATION RESULTS"
echo "========================================================================"
echo "Job ID: $JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Model: Enhanced BLIP3-o Patch-Level DiT"
echo "Evaluation Type: Comprehensive Cosine Similarity Analysis"
echo "Evaluation Duration: $EVAL_DURATION seconds"
echo "Total Runtime: $SECONDS seconds"
echo "Date: $(date)"

if [ $EXIT_CODE -eq 0 ]; then
    echo "Status: ‚úÖ SUCCESS - ENHANCED EVALUATION COMPLETED"
    
    # Find and display results from JSON files
    RESULTS_FILES=("$OUTPUT_DIR"/*evaluation*.json)
    SUMMARY_FILES=("$OUTPUT_DIR"/*summary*.json)
    
    echo ""
    echo "üìä ENHANCED EVALUATION RESULTS SUMMARY:"
    echo "======================================"
    
    # Parse and display summary results
    if [ ${#SUMMARY_FILES[@]} -gt 0 ] && [ -f "${SUMMARY_FILES[0]}" ]; then
        echo "üìã Summary Results:"
        python -c "
import json
import sys

try:
    with open('${SUMMARY_FILES[0]}', 'r') as f:
        data = json.load(f)
    
    if 'results_summary' in data:
        results = data['results_summary']
        print()
        print(f'üéØ COSINE SIMILARITY RESULTS:')
        print(f'   Global mean similarity:    {results.get(\"global_mean_similarity\", 0):.4f}')
        print(f'   Per-image mean similarity: {results.get(\"per_image_mean_similarity\", 0):.4f}')
        print(f'   Quality level:             {results.get(\"quality_level\", \"unknown\")}')
        print(f'   Total images evaluated:    {results.get(\"total_images\", 0):,}')
        print(f'   Total patches evaluated:   {results.get(\"total_patches\", 0):,}')
        print()
        
        # Performance assessment
        per_image_sim = results.get('per_image_mean_similarity', 0)
        if per_image_sim > 0.8:
            print(f'üéâ EXCELLENT: Outstanding patch-level alignment!')
            print(f'üöÄ Model shows excellent overfitting on training data')
        elif per_image_sim > 0.6:
            print(f'‚úÖ VERY GOOD: Strong patch-level performance')
            print(f'üéØ Model successfully learned patch-level mapping')
        elif per_image_sim > 0.4:
            print(f'üîÑ GOOD: Solid patch-level learning detected')
            print(f'üí° Model shows promise but can be improved')
        else:
            print(f'‚ö†Ô∏è  NEEDS IMPROVEMENT: Low patch-level similarity')
            print(f'üí° Consider longer training or hyperparameter tuning')
    
    print()
    print(f'üíæ Detailed results saved to: $OUTPUT_DIR')
    
    if 'files_generated' in data:
        files = data['files_generated']
        print(f'üìÅ Generated files:')
        for key, value in files.items():
            print(f'   {key}: {value}')

except Exception as e:
    print(f'‚ùå Could not parse evaluation summary: {e}')
    sys.exit(1)
"
    else
        echo "‚ö†Ô∏è  No summary file found, but evaluation completed"
    fi
    
    # Show output directory contents
    echo ""
    echo "üìÅ Generated Files:"
    echo "=================="
    ls -la "$OUTPUT_DIR" | head -20
    
    if [ $(ls -1 "$OUTPUT_DIR" | wc -l) -gt 20 ]; then
        echo "... and $(($(ls -1 "$OUTPUT_DIR" | wc -l) - 20)) more files"
    fi
    
    echo ""
    echo "‚úÖ ENHANCED EVALUATION COMPLETED SUCCESSFULLY"
    echo ""
    echo "üìã What was evaluated:"
    echo "   ‚úÖ Per-patch cosine similarity for each patch in each image"
    echo "   ‚úÖ Per-image average cosine similarity (mean of all patches)"
    echo "   ‚úÖ Global average cosine similarity (mean across all images)"
    echo "   ‚úÖ Quality distribution analysis and thresholds"
    echo "   ‚úÖ Advanced visualization plots and heatmaps"
    echo "   ‚úÖ Comprehensive JSON reporting for further analysis"
    echo ""
    echo "üéØ Key Metrics Computed:"
    echo "   ‚Ä¢ Individual patch similarities (256 or 257 per image)"
    echo "   ‚Ä¢ Per-image averages (single score per image)"
    echo "   ‚Ä¢ Global statistics (overall performance)"
    echo "   ‚Ä¢ Quality distributions (high/very high/excellent thresholds)"
    echo "   ‚Ä¢ Mode-specific analysis (CLS vs patch performance)"
    echo ""
    echo "üìä Next Steps:"
    echo "   ‚Ä¢ Review the comprehensive results in: $OUTPUT_DIR"
    echo "   ‚Ä¢ Analyze the visualization plots"
    echo "   ‚Ä¢ Use JSON data for further statistical analysis"
    echo "   ‚Ä¢ Compare results across different training modes"
    echo "   ‚Ä¢ Use insights to improve training pipeline"
    
else
    echo "Status: ‚ùå FAILED"
    echo ""
    echo "‚ùå ENHANCED EVALUATION FAILED WITH EXIT CODE: $EXIT_CODE"
    echo ""
    echo "üîç Troubleshooting:"
    echo "   1. Check if model path is correct and accessible"
    echo "   2. Verify embeddings directory and manifest file"
    echo "   3. Ensure GPU memory is sufficient"
    echo "   4. Check Python environment and dependencies"
    echo "   5. Verify model and embeddings compatibility"
    echo "   6. Look for error messages in the output above"
    echo ""
    echo "üìÇ Log files:"
    echo "   Output: ./slurm_out/blip3o_similarity_${JOB_ID}.out"
    echo "   Error:  ./slurm_out/blip3o_similarity_${JOB_ID}.err"
    echo ""
    echo "üîß Quick checks:"
    echo "   ‚Ä¢ Model path: $TRAINED_MODEL_PATH"
    echo "   ‚Ä¢ Embeddings: $EMBEDDINGS_DIR"
    echo "   ‚Ä¢ Available space: $(df -h . | tail -1 | awk '{print $4}')"
    echo "   ‚Ä¢ Training mode: $TRAINING_MODE"
fi

echo ""
echo "========================================================================"
echo "üèÅ ENHANCED EVALUATION SUMMARY"
echo "========================================================================"

# Always show final status prominently
if [ $EXIT_CODE -eq 0 ]; then
    echo "üéâ SUCCESS: Check the comprehensive evaluation results above!"
    echo ""
    echo "üìã What was accomplished:"
    echo "   ‚úÖ Comprehensive patch-level cosine similarity analysis"
    echo "   ‚úÖ Per-patch, per-image, and global similarity computation"
    echo "   ‚úÖ Advanced visualization plots and quality analysis"
    echo "   ‚úÖ Detailed JSON reporting for further analysis"
    echo "   ‚úÖ BLIP3-o paper aligned evaluation methodology"
    echo ""
    echo "üéØ Key Deliverables:"
    echo "   ‚Ä¢ Comprehensive similarity metrics at multiple granularities"
    echo "   ‚Ä¢ Quality distribution analysis with thresholds"
    echo "   ‚Ä¢ Advanced visualization plots for interpretation"
    echo "   ‚Ä¢ JSON data files for statistical analysis"
    echo "   ‚Ä¢ Mode-specific performance insights"
else
    echo "‚ùå FAILURE: Check error messages above and in log files"
    echo ""
    echo "üí° Troubleshooting:"
    echo "   ‚Ä¢ Verify model path: $TRAINED_MODEL_PATH"
    echo "   ‚Ä¢ Check embeddings: $EMBEDDINGS_DIR"
    echo "   ‚Ä¢ Ensure sufficient GPU memory"
    echo "   ‚Ä¢ Verify model-embeddings compatibility"
    echo "   ‚Ä¢ Check evaluation script and dependencies"
fi

echo "========================================================================"

# Cleanup temp cache
if [ -d "${JOB_TEMP}" ]; then
    echo "üßπ Cleaning up temporary cache..."
    rm -rf "${JOB_TEMP}"
fi

echo "üèÅ Enhanced evaluation job completed at $(date)"

exit $EXIT_CODE