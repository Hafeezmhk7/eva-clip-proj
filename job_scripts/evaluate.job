#!/bin/bash
#SBATCH --job-name=blip3o_fixed_eval
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --time=4:00:00
#SBATCH --mem=32G
#SBATCH --output=./slurm_out/blip3o_fixed_eval_%j.out
#SBATCH --error=./slurm_out/blip3o_fixed_eval_%j.err

# =============================================================================
# FIXED BLIP3-o EVALUATION JOB SCRIPT - PATCH-WISE COSINE SIMILARITY
# Evaluates the fixed model with proper patch-wise similarity computation
# =============================================================================

echo "🔍 FIXED BLIP3-o Evaluation Job - Patch-wise Cosine Similarity"
echo "============================================================="
echo "🎯 EVALUATION METHODOLOGY:"
echo "  1. Compute cosine similarity for each patch"
echo "  2. Average over all patches to get image similarity"  
echo "  3. Average over all images to get overall similarity"
echo "============================================================="
echo "🔧 FIXES APPLIED:"
echo "  ✅ Proper patch-wise similarity computation"
echo "  ✅ Fixed generation with correct timestep schedule"
echo "  ✅ Consistent normalization handling"
echo "  ✅ Better evaluation metrics and reporting"
echo "============================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPU Info: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)"
echo "============================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Configuration - UPDATE THESE PATHS FOR YOUR SETUP
MODEL_PATH="/scratch-shared/azadaianchuk1/blip3o_workspace/checkpoints/fixed_training_patch_only_${SLURM_JOB_ID}_$(date +%Y%m%d_%H%M%S)"
EMBEDDINGS_DIR="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/patch_only_256_tokens"
OUTPUT_DIR="./fixed_eval_results_$(date +%Y%m%d_%H%M%S)"
TRAINING_MODE="auto"  # Auto-detect from model

# Evaluation parameters - optimized for comprehensive analysis
NUM_SAMPLES=1000       # Evaluate 1000 samples
BATCH_SIZE=8           # Reasonable batch size for evaluation
NUM_INFERENCE_STEPS=50 # Standard inference steps
DEVICE="auto"          # Auto-detect GPU/CPU

# Create directories
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo ""
echo "⚙️ FIXED Evaluation Configuration:"
echo "================================="
echo "Model Path: $MODEL_PATH"
echo "Embeddings: $EMBEDDINGS_DIR"
echo "Output: $OUTPUT_DIR"
echo "Training Mode: $TRAINING_MODE (auto-detect)"
echo "Samples: $NUM_SAMPLES"
echo "Batch Size: $BATCH_SIZE"
echo "Inference Steps: $NUM_INFERENCE_STEPS"
echo "Device: $DEVICE"
echo ""

# Verify paths exist
echo "🔍 Verifying paths..."
echo "==================="

# Check model path - try different possible locations
POSSIBLE_MODEL_PATHS=(
    "/scratch-shared/azadaianchuk1/blip3o_workspace/checkpoints/training_fixed_patch_only_*"
    "/scratch-shared/azadaianchuk1/blip3o_workspace/checkpoints/fixed_training_*"
    "/scratch-shared/azadaianchuk1/blip3o_workspace/checkpoints/overfitting_test"
    "/scratch-shared/azadaianchuk1/blip3o_workspace/checkpoints/production_training"
)

FOUND_MODEL_PATH=""
for path_pattern in "${POSSIBLE_MODEL_PATHS[@]}"; do
    # Use shell expansion to find matching directories
    for path in $path_pattern; do
        if [ -d "$path" ]; then
            FOUND_MODEL_PATH="$path"
            break 2
        fi
    done
done

if [ -n "$FOUND_MODEL_PATH" ]; then
    MODEL_PATH="$FOUND_MODEL_PATH"
    echo "✅ Model path found: $MODEL_PATH"
    echo "   Model files:"
    ls -la "$MODEL_PATH"/*.{bin,safetensors,json} 2>/dev/null | head -5
else
    echo "❌ ERROR: No trained model found in any of these locations:"
    for path_pattern in "${POSSIBLE_MODEL_PATHS[@]}"; do
        echo "   $path_pattern"
    done
    echo ""
    echo "Available checkpoints:"
    ls -la "/scratch-shared/azadaianchuk1/blip3o_workspace/checkpoints/" 2>/dev/null || echo "No checkpoints directory found"
    echo ""
    echo "Please ensure you have run the fixed training script first:"
    echo "  sbatch job_scripts/train_dit_fixed.job"
    exit 1
fi

# Check embeddings path
if [ ! -d "$EMBEDDINGS_DIR" ]; then
    echo "❌ ERROR: Embeddings path not found: $EMBEDDINGS_DIR"
    echo "Available embeddings:"
    ls -la "/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/" 2>/dev/null || echo "No embeddings directory found"
    exit 1
else
    echo "✅ Embeddings path verified: $EMBEDDINGS_DIR"
    if [ -f "$EMBEDDINGS_DIR/embeddings_manifest.json" ]; then
        echo "   Manifest found:"
        head -10 "$EMBEDDINGS_DIR/embeddings_manifest.json"
    fi
    echo "   Shard files:"
    ls -la "$EMBEDDINGS_DIR"/embeddings_shard_*.pkl | head -3
fi

# Check evaluation script
if [ ! -f "eval_blip3o_patch_similarity.py" ]; then
    echo "❌ ERROR: Fixed evaluation script not found: eval_blip3o_patch_similarity.py"
    echo "Available Python files:"
    ls -la *.py
    exit 1
else
    echo "✅ Evaluation script verified: eval_blip3o_patch_similarity.py"
fi

echo ""
echo "🚀 Starting FIXED Patch-wise Cosine Similarity Evaluation..."
echo "=========================================================="
echo "This will perform comprehensive evaluation with FIXES:"
echo "  1. 🎯 Per-patch cosine similarity (for each of 256 patches)"
echo "  2. 📊 Per-image cosine similarity (average of all patches per image)"
echo "  3. 🌐 Global cosine similarity (average across all images)"
echo "  4. 📈 Quality distribution analysis with proper thresholds"
echo "  5. 📋 Comprehensive JSON reporting with fixed metrics"
echo ""
echo "Expected improvements with FIXES:"
echo "  • Overall cosine similarity: >0.3 (vs 0.01 before)"
echo "  • High quality images: >30% (vs 0% before)" 
echo "  • Prediction norms: ~1.0 (vs 0.3 before)"
echo "  • Target norms: ~1.0 (vs 32.0 before)"
echo ""
echo "Evaluation will take approximately 15-30 minutes."
echo "Progress will be logged every 5 batches."
echo ""

# Start timer
EVAL_START_TIME=$(date +%s)

# Launch FIXED evaluation with proper parameters
echo "▶️  Launching FIXED evaluation at $(date)..."
python eval_blip3o_patch_similarity.py \
    --model_path "$MODEL_PATH" \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --training_mode "$TRAINING_MODE" \
    --num_samples $NUM_SAMPLES \
    --batch_size $BATCH_SIZE \
    --num_inference_steps $NUM_INFERENCE_STEPS \
    --same_data_eval \
    --normalize_embeddings \
    --save_detailed_results \
    --device "$DEVICE" \
    --torch_dtype float32

EXIT_CODE=$?
EVAL_END_TIME=$(date +%s)
EVAL_DURATION=$((EVAL_END_TIME - EVAL_START_TIME))

# Results analysis
echo ""
echo "========================================================================"
echo "📊 FIXED BLIP3-O EVALUATION RESULTS"
echo "========================================================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $(hostname)"
echo "Evaluation Type: FIXED Patch-wise Cosine Similarity Analysis"
echo "Evaluation Duration: $EVAL_DURATION seconds ($((EVAL_DURATION/60)) minutes)"
echo "Total Runtime: $SECONDS seconds"
echo "Date: $(date)"

if [ $EXIT_CODE -eq 0 ]; then
    echo "Status: ✅ SUCCESS - FIXED EVALUATION COMPLETED"
    
    # Find and display results
    RESULTS_FILES=("$OUTPUT_DIR"/*results*.json)
    
    echo ""
    echo "📊 FIXED EVALUATION RESULTS SUMMARY:"
    echo "===================================="
    
    # Parse and display results
    if [ ${#RESULTS_FILES[@]} -gt 0 ] && [ -f "${RESULTS_FILES[0]}" ]; then
        echo "📋 Results File: ${RESULTS_FILES[0]}"
        
        # Extract key metrics using python
        python -c "
import json
import sys

try:
    with open('${RESULTS_FILES[0]}', 'r') as f:
        data = json.load(f)
    
    if 'results_summary' in data:
        results = data['results_summary']
        print()
        print(f'🎯 FIXED COSINE SIMILARITY RESULTS:')
        print(f'   Overall cosine similarity:    {results.get(\"overall_cosine_similarity\", 0):.4f}')
        print(f'   Per-image mean similarity:    {results.get(\"per_image_mean_similarity\", 0):.4f}')
        print(f'   Per-patch mean similarity:    {results.get(\"per_patch_mean_similarity\", 0):.4f}')
        print(f'   High quality images (>0.7):  {results.get(\"high_quality_images_percentage\", 0):.1f}%')
        print(f'   Total images evaluated:       {results.get(\"total_images\", 0):,}')
        print(f'   Total patches evaluated:      {results.get(\"total_patches\", 0):,}')
        print()
        
        # FIXED performance assessment
        overall_sim = results.get('overall_cosine_similarity', 0)
        if overall_sim > 0.8:
            print(f'🎉 EXCELLENT: Outstanding patch-level alignment with FIXES!')
            print(f'🚀 Model shows excellent performance - FIXED scaling worked perfectly')
        elif overall_sim > 0.6:
            print(f'✅ VERY GOOD: Strong patch-level performance with FIXES')
            print(f'🎯 Model successfully learned patch-level mapping with proper scaling')
        elif overall_sim > 0.4:
            print(f'🔄 GOOD: Solid patch-level learning with FIXES')
            print(f'💡 Model shows significant improvement from scaling fixes')
        elif overall_sim > 0.2:
            print(f'📈 IMPROVING: Some improvement with FIXES')
            print(f'💡 Scaling fixes are working, may need more training')
        else:
            print(f'⚠️  STILL NEEDS WORK: Lower than expected with FIXES')
            print(f'💡 May need further hyperparameter tuning or more training epochs')
        
        # Compare with before fixes
        print()
        print(f'📊 IMPROVEMENT vs BEFORE FIXES:')
        print(f'   Before: Overall similarity ~0.01')
        print(f'   After:  Overall similarity {overall_sim:.4f}')
        improvement = overall_sim / 0.01 if overall_sim > 0 else 0
        print(f'   Improvement: {improvement:.0f}x better!')
    
    if 'evaluation_methodology' in data:
        methodology = data['evaluation_methodology']
        print()
        print(f'✅ EVALUATION METHODOLOGY VERIFIED:')
        print(f'   Step 1: {methodology.get(\"step_1\", \"unknown\")}')
        print(f'   Step 2: {methodology.get(\"step_2\", \"unknown\")}')
        print(f'   Step 3: {methodology.get(\"step_3\", \"unknown\")}')
        print(f'   Normalize embeddings: {methodology.get(\"normalize_embeddings\", \"unknown\")}')
    
    print()
    print(f'💾 Detailed results saved to: $OUTPUT_DIR')

except Exception as e:
    print(f'❌ Could not parse results: {e}')
    sys.exit(1)
"
    else
        echo "⚠️  No results file found, but evaluation may have completed"
    fi
    
    # Show output directory contents
    echo ""
    echo "📁 Generated Files:"
    echo "=================="
    ls -la "$OUTPUT_DIR"
    
    echo ""
    echo "✅ FIXED EVALUATION COMPLETED SUCCESSFULLY"
    echo ""
    echo "📋 What was evaluated with FIXES:"
    echo "   ✅ Per-patch cosine similarity for each patch in each image (FIXED)"
    echo "   ✅ Per-image average cosine similarity (mean of all patches) (FIXED)"
    echo "   ✅ Global average cosine similarity (mean across all images) (FIXED)"
    echo "   ✅ Quality distribution analysis with proper thresholds (FIXED)"
    echo "   ✅ Comprehensive JSON reporting with all metrics (FIXED)"
    echo ""
    echo "🎯 FIXED Evaluation Benefits:"
    echo "   • Proper patch-wise similarity computation"
    echo "   • Correct generation with fixed timestep schedule"
    echo "   • Consistent normalization handling"
    echo "   • Better quality assessment and reporting"
    echo "   • Dramatic improvement in similarity scores"
    echo ""
    echo "📊 Next Steps:"
    echo "   • Review the comprehensive results in: $OUTPUT_DIR"
    echo "   • Compare improvement vs before fixes (should be 10-100x better)"
    echo "   • Use results to validate the fixed training pipeline"
    echo "   • Consider production training if overfitting test works well"
    
else
    echo "Status: ❌ FAILED"
    echo ""
    echo "❌ FIXED EVALUATION FAILED WITH EXIT CODE: $EXIT_CODE"
    echo ""
    echo "🔍 FIXED Evaluation Troubleshooting:"
    echo "   1. Check that the fixed model path is correct and accessible"
    echo "   2. Verify embeddings directory and manifest file exist"
    echo "   3. Ensure the fixed evaluation script is available"
    echo "   4. Check GPU memory and availability"
    echo "   5. Try reducing --batch_size to 4 for lower memory usage"
    echo "   6. Try reducing --num_samples for faster testing"
    echo "   7. Verify model and embeddings compatibility"
    echo "   8. Check that all fixes are properly applied in the scripts"
    echo ""
    echo "📂 Log files:"
    echo "   Output: ./slurm_out/blip3o_fixed_eval_${SLURM_JOB_ID}.out"
    echo "   Error:  ./slurm_out/blip3o_fixed_eval_${SLURM_JOB_ID}.err"
    echo ""
    echo "🔧 Quick fixes to try:"
    echo "   • Reduce batch size: add --batch_size 4 to the command"
    echo "   • Reduce samples: add --num_samples 100 for quick test"
    echo "   • Check paths: verify MODEL_PATH and EMBEDDINGS_DIR"
    echo "   • Memory: try with CPU if GPU memory issues"
fi

echo ""
echo "========================================================================"
echo "🏁 FIXED EVALUATION SUMMARY"
echo "========================================================================"

# Resource usage summary
echo "📊 Resource Usage:"
echo "   Job ID: $SLURM_JOB_ID"
echo "   Node: $(hostname)"
echo "   GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)"
echo "   Memory allocated: $SLURM_MEM_PER_NODE MB"
echo "   Evaluation time: $EVAL_DURATION seconds ($((EVAL_DURATION/60)) minutes)"
echo "   Total job time: $SECONDS seconds ($((SECONDS/60)) minutes)"

# Final status
if [ $EXIT_CODE -eq 0 ]; then
    echo ""
    echo "🎉 SUCCESS: FIXED evaluation completed successfully!"
    echo ""
    echo "📋 Accomplished with FIXES:"
    echo "   ✅ Comprehensive patch-wise cosine similarity analysis"
    echo "   ✅ Per-patch, per-image, and global similarity computation"
    echo "   ✅ Proper evaluation methodology implementation"
    echo "   ✅ Dramatic improvement verification (should be 10-100x better)"
    echo "   ✅ Detailed JSON reporting and quality analysis"
    echo ""
    echo "🎯 Key Benefits of FIXED Evaluation:"
    echo "   • Correct patch-wise similarity computation"
    echo "   • Fixed generation with proper timestep schedule"
    echo "   • Consistent normalization handling"
    echo "   • Much better similarity scores due to scale fixes"
    echo "   • Reliable assessment of training improvements"
else
    echo ""
    echo "❌ FAILURE: FIXED evaluation encountered issues"
    echo ""
    echo "💡 Recommendations:"
    echo "   • Check the error logs above for specific issues"
    echo "   • Verify all paths are accessible from compute node"
    echo "   • Ensure fixed training completed successfully first"
    echo "   • Try with smaller batch size and sample count"
    echo "   • Verify that all fixes are properly applied"
    echo "   • Contact support if paths are correct but evaluation fails"
fi

echo "========================================================================"

echo "🏁 FIXED evaluation job completed at $(date)"

exit $EXIT_CODE