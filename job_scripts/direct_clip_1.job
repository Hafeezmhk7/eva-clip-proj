#!/bin/bash
#SBATCH --job-name=comprehensive_clip_blip3o_eval
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --cpus-per-gpu=18
#SBATCH --time=3:00:00
#SBATCH --mem=0
#SBATCH --output=./slurm_out/comprehensive_eval_%j.out
#SBATCH --error=./slurm_out/comprehensive_eval_%j.err

# =============================================================================
# COMPREHENSIVE CLIP AND BLIP3O EVALUATION JOB
# Tests: Global Token, Patch-based, and BLIP3o recall methods
# =============================================================================

echo "üöÄ Comprehensive CLIP and BLIP3o Evaluation"
echo "==========================================="

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

source activate eva_clip_env

# Configuration
COCO_ROOT="./data/coco"
NUM_SAMPLES=1000
BATCH_SIZE=32
DEVICE="cuda"
EVALUATION_METHOD="all"  # Test all methods: global, patch, blip3o

# BLIP3o model path (your trained model)
BLIP3O_MODEL_PATH="/scratch-shared/scur2711/blip3o_workspace/checkpoints/blip3o_multi_gpu_fixed_cosine_13173833_20250716_085748"

# Setup temp directories for model cache
export USER=$(whoami)
export JOB_ID=${SLURM_JOB_ID}
export JOB_TEMP="/scratch-local/${USER}.${JOB_ID}/comprehensive_eval"

export TORCH_HOME="${JOB_TEMP}/torch"
export HF_HOME="${JOB_TEMP}/huggingface"
export TRANSFORMERS_CACHE="${JOB_TEMP}/transformers"

mkdir -p "${TORCH_HOME}" "${HF_HOME}" "${TRANSFORMERS_CACHE}"
mkdir -p ./slurm_out ./results

echo "Configuration:"
echo "  COCO Root: $COCO_ROOT"
echo "  Samples: $NUM_SAMPLES"
echo "  Batch Size: $BATCH_SIZE"
echo "  Device: $DEVICE"
echo "  Method: $EVALUATION_METHOD"
echo "  BLIP3o Model: $BLIP3O_MODEL_PATH"
echo "  Job ID: $JOB_ID"
echo "  Node: $SLURMD_NODENAME"

# Verify COCO data exists
echo ""
echo "üîç Verifying data and model paths..."
echo "==================================="

if [ ! -d "$COCO_ROOT" ]; then
    echo "‚ùå ERROR: COCO data not found at $COCO_ROOT"
    exit 1
fi

if [ ! -f "$COCO_ROOT/annotations/captions_val2017.json" ]; then
    echo "‚ùå ERROR: COCO annotations not found"
    exit 1
fi

if [ ! -d "$BLIP3O_MODEL_PATH" ]; then
    echo "‚ùå ERROR: BLIP3o model not found at $BLIP3O_MODEL_PATH"
    echo "   Available checkpoints:"
    ls -la /scratch-shared/scur2711/blip3o_workspace/checkpoints/ 2>/dev/null || echo "   No checkpoints found"
    exit 1
fi

echo "‚úÖ COCO data verified"
echo "‚úÖ BLIP3o model verified"

# Run comprehensive evaluation
echo ""
echo "üîç Starting comprehensive evaluation..."
echo "====================================="
echo "Testing methods:"
echo "  1. üéØ Global Token (CLS + visual projection)"
echo "  2. üìä Patch-based (averaged patches + visual projection)"
echo "  3. ü§ñ BLIP3o (EVA ‚Üí DiT ‚Üí visual projection)"
echo ""

EVAL_START_TIME=$(date +%s)

python direct_clip_evaluation.py \
    --coco_root "$COCO_ROOT" \
    --num_samples $NUM_SAMPLES \
    --device $DEVICE \
    --method $EVALUATION_METHOD \
    --blip3o_model_path "$BLIP3O_MODEL_PATH" \
    --k_values 1 5 10 20 \
    --save_results "results/comprehensive_evaluation_${JOB_ID}.json"

EXIT_CODE=$?
EVAL_END_TIME=$(date +%s)
EVAL_DURATION=$((EVAL_END_TIME - EVAL_START_TIME))

# Results summary - PARSE AND DISPLAY RESULTS IN JOB OUTPUT
echo ""
echo "========================================================================"
echo "üìä COMPREHENSIVE EVALUATION RESULTS"
echo "========================================================================"
echo "Job ID: $JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Evaluation Duration: $EVAL_DURATION seconds"
echo "Total Runtime: $SECONDS seconds"
echo "Date: $(date)"

if [ $EXIT_CODE -eq 0 ]; then
    echo "Status: ‚úÖ SUCCESS - COMPREHENSIVE EVALUATION COMPLETED"
    
    # Find and display results from JSON file
    RESULTS_FILE="results/comprehensive_evaluation_${JOB_ID}.json"
    if [ -f "$RESULTS_FILE" ]; then
        echo ""
        echo "üìä COMPREHENSIVE RESULTS SUMMARY:"
        echo "=================================="
        
        # Parse JSON results and display prominently
        if command -v python3 &> /dev/null; then
            python3 << EOF
import json
import sys

try:
    with open('$RESULTS_FILE', 'r') as f:
        data = json.load(f)
    
    method_results = data.get('method_results', {})
    eval_info = data.get('evaluation_info', {})
    
    print()
    print("üéØ RECALL@1 COMPARISON:")
    print("-" * 50)
    
    results_summary = {}
    for method, results in method_results.items():
        if 'error' not in results and 'recall@1' in results:
            r1 = results['recall@1'] * 100
            r5 = results.get('recall@5', 0) * 100
            r10 = results.get('recall@10', 0) * 100
            time_taken = results.get('evaluation_time', 0)
            description = results.get('method_description', method)
            
            results_summary[method] = {
                'r1': r1, 'r5': r5, 'r10': r10, 'time': time_taken, 'desc': description
            }
            
            print(f"   {method.upper():>8s}: {r1:5.1f}% | R@5: {r5:5.1f}% | R@10: {r10:5.1f}% | Time: {time_taken:5.1f}s")
            print(f"            {description[:65]}")
            print()
    
    print("-" * 50)
    
    # Literature comparison
    if 'global' in results_summary:
        global_r1 = results_summary['global']['r1']
        print(f"üìö Literature Comparison:")
        print(f"   Expected CLIP ViT-L/14 R@1: ~58-60%")
        print(f"   Your Global Token R@1:     {global_r1:.1f}%")
        
        if global_r1 >= 58:
            print(f"   ‚úÖ EXCELLENT: Matches/exceeds literature!")
        elif global_r1 >= 55:
            print(f"   ‚úÖ GOOD: Close to literature values")
        else:
            print(f"   ‚ö†Ô∏è  LOW: Below expected literature values")
        print()
    
    # Method comparison
    if len(results_summary) > 1:
        print(f"üìà Method Performance Analysis:")
        
        # Compare against global token as baseline
        if 'global' in results_summary:
            baseline = results_summary['global']['r1']
            baseline_method = 'global'
        else:
            baseline_method = list(results_summary.keys())[0]
            baseline = results_summary[baseline_method]['r1']
        
        print(f"   Baseline ({baseline_method}): {baseline:.1f}%")
        print()
        
        for method, result in results_summary.items():
            if method != baseline_method:
                diff = result['r1'] - baseline
                diff_pct = (diff / baseline) * 100 if baseline > 0 else 0
                
                if method == 'patch':
                    print(f"   üìä Patch vs Global:")
                    print(f"      Difference: {diff:+.1f}% ({diff_pct:+.1f}%)")
                    if abs(diff) < 2:
                        print(f"      Status: ‚úÖ Similar performance (expected)")
                    elif diff > 0:
                        print(f"      Status: üìà Patch outperforms (unexpected but good)")
                    else:
                        print(f"      Status: üìâ Global outperforms (expected)")
                    print()
                
                elif method == 'blip3o':
                    print(f"   ü§ñ BLIP3o vs Global:")
                    print(f"      Difference: {diff:+.1f}% ({diff_pct:+.1f}%)")
                    if diff >= -2:  # Within 2% is good
                        print(f"      Status: ‚úÖ EXCELLENT - Preserves CLIP performance!")
                        print(f"      Your BLIP3o model is working well!")
                    elif diff >= -5:  # Within 5% is acceptable
                        print(f"      Status: ‚úÖ GOOD - Minor performance drop")
                        print(f"      BLIP3o slightly underperforms but acceptable")
                    else:
                        print(f"      Status: ‚ö†Ô∏è  NEEDS IMPROVEMENT - Significant drop")
                        print(f"      Consider training adjustments or architecture changes")
                    print()
    
    # Overall assessment
    print("üéØ OVERALL ASSESSMENT:")
    print("-" * 30)
    
    if 'blip3o' in results_summary and 'global' in results_summary:
        blip3o_r1 = results_summary['blip3o']['r1']
        global_r1 = results_summary['global']['r1']
        
        if blip3o_r1 >= global_r1 - 2:
            print("üéâ SUCCESS: BLIP3o successfully learned EVA‚ÜíCLIP mapping!")
            print("   Your model preserves CLIP's retrieval capabilities.")
            print("   Ready for production use or further research.")
        elif blip3o_r1 >= global_r1 - 5:
            print("‚úÖ GOOD: BLIP3o shows promising results.")
            print("   Minor performance gap suggests room for improvement.")
            print("   Consider fine-tuning hyperparameters or training longer.")
        else:
            print("‚ö†Ô∏è  IMPROVEMENT NEEDED: Significant performance gap.")
            print("   Suggests issues with model architecture or training.")
            print("   Review loss curves, data quality, and model design.")
    else:
        print("üìä Partial evaluation completed.")
        print("   Check individual method results above.")
    
    print()
    print(f"üíæ Full results saved to: $RESULTS_FILE")

except Exception as e:
    print(f"‚ùå Could not parse results file: {e}")
    sys.exit(1)
EOF
        else
            echo "‚ö†Ô∏è  Python not available to parse results"
            echo "   Results file: $RESULTS_FILE"
        fi
    else
        echo "‚ö†Ô∏è  No results file found"
        echo "   Evaluation may have completed without saving results"
        echo "   Check the output above for inline results"
    fi
    
    echo ""
    echo "‚úÖ COMPREHENSIVE EVALUATION COMPLETED SUCCESSFULLY"
    
else
    echo "Status: ‚ùå FAILED"
    echo ""
    echo "‚ùå COMPREHENSIVE EVALUATION FAILED WITH EXIT CODE: $EXIT_CODE"
    echo ""
    echo "üîç Troubleshooting:"
    echo "   1. Check if COCO data exists and is accessible"
    echo "   2. Verify BLIP3o model path is correct"
    echo "   3. Ensure GPU memory is sufficient for all models"
    echo "   4. Check Python environment and dependencies"
    echo "   5. Verify BLIP3o inference module is available"
    echo "   6. Look for error messages in the output above"
    echo ""
    echo "üìÇ Log files:"
    echo "   Output: ./slurm_out/comprehensive_eval_${JOB_ID}.out"
    echo "   Error:  ./slurm_out/comprehensive_eval_${JOB_ID}.err"
    echo ""
    echo "üîß Quick checks:"
    echo "   ‚Ä¢ COCO path: $COCO_ROOT"
    echo "   ‚Ä¢ BLIP3o model: $BLIP3O_MODEL_PATH"
    echo "   ‚Ä¢ Available space: $(df -h . | tail -1 | awk '{print $4}')"
fi

echo ""
echo "========================================================================"
echo "üèÅ COMPREHENSIVE EVALUATION SUMMARY"
echo "========================================================================"

# Always show final status prominently
if [ $EXIT_CODE -eq 0 ]; then
    echo "üéâ SUCCESS: Check the comprehensive results above!"
    echo ""
    echo "üìã What was tested:"
    echo "   ‚úÖ Global Token Method (CLS + visual projection)"
    echo "   ‚úÖ Patch-based Method (averaged patches + visual projection)"
    echo "   ‚úÖ BLIP3o Method (EVA ‚Üí DiT ‚Üí visual projection)"
    echo ""
    echo "üéØ Key Questions Answered:"
    echo "   ‚Ä¢ Does your CLIP implementation match literature? (Global method)"
    echo "   ‚Ä¢ How does patch averaging compare to CLS token? (Patch vs Global)"
    echo "   ‚Ä¢ Does BLIP3o preserve CLIP's capabilities? (BLIP3o vs Global)"
    echo ""
    echo "üìä Next Steps:"
    echo "   ‚Ä¢ Review the method comparison above"
    echo "   ‚Ä¢ Check if BLIP3o performance meets your requirements"
    echo "   ‚Ä¢ Use results to guide further model development"
else
    echo "‚ùå FAILURE: Check error messages above and in log files"
    echo ""
    echo "üí° Common Issues:"
    echo "   ‚Ä¢ BLIP3o model path incorrect or model corrupted"
    echo "   ‚Ä¢ Insufficient GPU memory for large models"
    echo "   ‚Ä¢ Missing dependencies in eva_clip_env environment"
    echo "   ‚Ä¢ COCO dataset path or permissions issues"
fi

echo "========================================================================"

# Cleanup temp cache
if [ -d "${JOB_TEMP}" ]; then
    echo "üßπ Cleaning up temporary cache..."
    rm -rf "${JOB_TEMP}"
fi

echo "üèÅ Job completed at $(date)"

exit $EXIT_CODE