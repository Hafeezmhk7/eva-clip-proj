#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --job-name=blip3o_dit_training
#SBATCH --time=24:00:00
#SBATCH --output=./slurm_out/train_%j.out
#SBATCH --error=./slurm_out/train_%j.err
#SBATCH --mem=64GB
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1

echo "üöÄ Starting BLIP3-o DiT Training Job - FIXED VERSION"
echo "=================================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURMD_NODENAME" 
echo "Date: $(date)"
echo "Working directory: $(pwd)"
echo "CUDA Visible Devices: $CUDA_VISIBLE_DEVICES"

# Create output directories
mkdir -p slurm_out
mkdir -p production_checkpoints

# Load modules
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

# Activate conda environment
source activate eva_clip_env

# Check if embeddings file exists
EMBEDDINGS_FILE="embeddings/blip3o_grid_embeddings.pkl"

echo "üîç Checking for embeddings file..."
if [ ! -f "$EMBEDDINGS_FILE" ]; then
    echo "‚ùå Embeddings file not found: $EMBEDDINGS_FILE"
    echo ""
    echo "Please extract embeddings first:"
    echo "  sbatch job_scripts/extract_emb.job"
    echo ""
    echo "Or run extraction manually:"
    echo "  python src/modules/extract_embeddings_g.py"
    exit 1
fi

echo "‚úÖ Found embeddings file: $EMBEDDINGS_FILE"
echo "üìä File size: $(du -sh $EMBEDDINGS_FILE | cut -f1)"

# Validate embeddings format
echo "üß™ Validating embeddings format..."
python -c "
import pickle
import sys

try:
    with open('$EMBEDDINGS_FILE', 'rb') as f:
        data = pickle.load(f)
    
    # Check required keys for BLIP3-o
    required_keys = ['clip_blip3o_embeddings', 'eva_blip3o_embeddings']
    for key in required_keys:
        if key not in data:
            print(f'‚ùå Missing required key: {key}')
            sys.exit(1)
    
    # Check dimensions
    clip_shape = data['clip_blip3o_embeddings'].shape
    eva_shape = data['eva_blip3o_embeddings'].shape
    
    print(f'üìê CLIP BLIP3-o embeddings: {clip_shape}')
    print(f'üìê EVA BLIP3-o embeddings: {eva_shape}')
    
    # Validate shapes for BLIP3-o DiT
    if len(clip_shape) != 3 or clip_shape[1] != 64 or clip_shape[2] != 1024:
        print(f'‚ùå Invalid CLIP shape: {clip_shape}, expected [N, 64, 1024]')
        sys.exit(1)
        
    if len(eva_shape) != 3 or eva_shape[1] != 64 or eva_shape[2] != 4096:
        print(f'‚ùå Invalid EVA shape: {eva_shape}, expected [N, 64, 4096]')
        sys.exit(1)
    
    total_samples = data.get('total_samples', clip_shape[0])
    print(f'‚úÖ Embeddings validation passed!')
    print(f'   Total samples: {total_samples}')
    print(f'   CLIP: ViT-L/14 features (1024-dim)')
    print(f'   EVA: EVA-CLIP-8B features (4096-dim)')
    
except Exception as e:
    print(f'‚ùå Embeddings validation failed: {e}')
    sys.exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå Embeddings validation failed!"
    exit 1
fi

echo "‚úÖ Embeddings validation passed!"

# Show system information
echo ""
echo "üíæ System Information:"
echo "   GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits)"
echo "   GPU Memory: $(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits) MB"
echo "   CPU Cores: $SLURM_CPUS_PER_TASK"
echo "   System Memory: $SLURM_MEM_PER_NODE MB"

# Check available disk space
echo "   Available Disk: $(df -h . | tail -1 | awk '{print $4}')"

# Start training with correct embeddings path
echo ""
echo "üöÄ Starting BLIP3-o DiT Training..."
echo "=================================="

python train_blip3o_dit.py \
  --embeddings_path "$EMBEDDINGS_FILE" \
  --output_dir ./production_checkpoints \
  --batch_size 64 \  # Increased batch size
  --num_epochs 5 \   # Reduced epochs
  --device cuda \
  --fp16 \
  --compile_model \
  --gradient_checkpointing \
  --learning_rate 5e-5 \
  --warmup_steps 20 \
  --logging_steps 10 \  # Less frequent logging
  --save_steps 200 \   # Less frequent saving
  --eval_steps 50 \    # Less frequent evaluation
  --wandb_project "blip3o-dit-production" \
  --wandb_run_name "blip3o-dit-$(date +%Y%m%d-%H%M%S)"

# Check training exit code
TRAINING_EXIT_CODE=$?

echo ""
if [ $TRAINING_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ BLIP3-o DiT training completed successfully!"
    echo ""
    echo "üìÅ Training outputs:"
    ls -lh production_checkpoints/
    echo ""
    
    # Show final model info
    if [ -d "production_checkpoints" ]; then
        echo "üéâ Training completed successfully!"
        echo "üìä Final model location: production_checkpoints/"
        
        # Check for pytorch_model.bin or model weights
        if [ -f "production_checkpoints/pytorch_model.bin" ]; then
            echo "‚úÖ Model weights saved: pytorch_model.bin"
            echo "üìä Model size: $(du -sh production_checkpoints/pytorch_model.bin | cut -f1)"
        fi
        
        # Check for config files
        if [ -f "production_checkpoints/config.json" ]; then
            echo "‚úÖ Model config saved: config.json"
        fi
        
        # Check for training logs
        if [ -f "production_checkpoints/training.log" ]; then
            echo "‚úÖ Training logs saved: training.log"
            echo "üìù Last few training lines:"
            tail -5 production_checkpoints/training.log
        fi
        
        echo ""
        echo "üöÄ Next steps:"
        echo "1. Test inference with your trained model"
        echo "2. Generate sample CLIP embeddings from EVA-CLIP conditioning"
        echo "3. Evaluate model performance on held-out data"
        
    fi
    
else
    echo "‚ùå BLIP3-o DiT training failed with exit code: $TRAINING_EXIT_CODE"
    
    echo ""
    echo "üîç Debugging information:"
    
    # Check GPU memory
    echo "GPU Memory Status:"
    nvidia-smi
    
    # Check if any checkpoints were saved
    if [ -d "production_checkpoints" ] && [ "$(ls -A production_checkpoints)" ]; then
        echo ""
        echo "üìÅ Partial training outputs found:"
        ls -lh production_checkpoints/
        echo "   You may be able to resume training from these checkpoints"
    fi
    
    # Check logs for errors
    if [ -f "production_checkpoints/training.log" ]; then
        echo ""
        echo "üìù Last training log entries:"
        tail -10 production_checkpoints/training.log
    fi
    
    exit 1
fi

# Show final system status
echo ""
echo "üìä Final System Status:"
echo "   GPU Memory:"
nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits
echo "   Disk Usage:"
df -h . | head -2

echo ""
echo "üéâ BLIP3-o DiT Job completed at: $(date)"
echo "‚è±Ô∏è Total runtime: $SECONDS seconds"

# Final success message
if [ $TRAINING_EXIT_CODE -eq 0 ]; then
    echo ""
    echo "üéØ SUCCESS SUMMARY:"
    echo "‚úÖ Embeddings: BLIP3-o compatible format (CLIP: 1024-dim, EVA: 4096-dim)"
    echo "‚úÖ Architecture: BLIP3-o DiT with proper 3D RoPE and flow matching"
    echo "‚úÖ Training: Completed successfully with flow matching loss"
    echo "‚úÖ Model: Saved to production_checkpoints/"
    echo ""
    echo "Your BLIP3-o model is ready for inference! üöÄ"
fi