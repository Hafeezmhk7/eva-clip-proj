#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --job-name=lumina_train
#SBATCH --time=24:00:00          # Increased for training
#SBATCH --output=./slurm_out/train_%j.out
#SBATCH --error=./slurm_out/train_%j.err
#SBATCH --mem=64GB               # Increased memory
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1

echo "ðŸš€ Starting Lumina-DiT Training Job"
echo "=============================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Date: $(date)"
echo "Working directory: $(pwd)"
echo "CUDA Visible Devices: $CUDA_VISIBLE_DEVICES"

# Create output directories
mkdir -p slurm_out
mkdir -p checkpoints

# Load modules
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

# Activate conda environment
source activate eva_clip_env


python train_flow_matching.py \
  --embedding_path embeddings/blip3o_embeddings.pkl \
  --save_dir checkpoints_original \
  --batch_size 64 \
  --dim 1024 \
  --depth 24 \
  --num_heads 16 \
  --num_kv_heads 8 \
  --lr 2e-4 \
  --epochs 100 \
  --force_original \
  --loss_type huber \
  --scheduler cosine_restarts