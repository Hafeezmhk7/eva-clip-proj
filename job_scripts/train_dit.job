#!/bin/bash
#SBATCH --job-name=blip3o_fixed_training
#SBATCH --partition=gpu_a100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-gpu=9
#SBATCH --time=12:00:00
#SBATCH --mem=64GB
#SBATCH --output=./slurm_out/blip3o_fixed_training_%j.out
#SBATCH --error=./slurm_out/blip3o_fixed_training_%j.err

# =============================================================================
# FIXED BLIP3-o TRAINING JOB SCRIPT - WITH PROPER SCALING
# Uses the new fixed training script with scale mismatch solutions
# =============================================================================

echo "üöÄ Starting FIXED BLIP3-o Training Job with Proper Scaling"
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "============================================================"
echo "üîß CRITICAL FIXES APPLIED:"
echo "  ‚úÖ Velocity scaling (velocity_scale=0.1)"
echo "  ‚úÖ Output scaling (output_scale=0.1)" 
echo "  ‚úÖ Adaptive norm alignment"
echo "  ‚úÖ Proper rectified flow implementation"
echo "  ‚úÖ Fixed generation timestep schedule"
echo "============================================================"

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Workspace setup
export USER=$(whoami)
export JOB_ID=${SLURM_JOB_ID}
export WORKSPACE="/scratch-shared/${USER}/blip3o_workspace"
export EMBEDDINGS_DIR="${WORKSPACE}/embeddings"
export CHECKPOINTS="${WORKSPACE}/checkpoints"

# FIXED Configuration - with proper scaling parameters
TRAINING_MODE="patch_only"  # patch_only or cls_patch
EMBEDDINGS_DIR="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/patch_only_256_tokens"
OUTPUT_DIR="${CHECKPOINTS}/fixed_training_${TRAINING_MODE}_${JOB_ID}_$(date +%Y%m%d_%H%M%S)"
mkdir -p "${OUTPUT_DIR}"

# FIXED Training parameters - addressing scale mismatch
MODEL_SIZE="base"
NUM_EPOCHS=8  # More epochs to see improvement
BATCH_SIZE=64  # Reasonable batch size
LEARNING_RATE=1e-4  # Slightly higher LR for faster learning
GRADIENT_ACCUMULATION_STEPS=2
LOGGING_STEPS=5
SAVE_STEPS=100

# CRITICAL: Scale parameters to fix norm mismatch
VELOCITY_SCALE=0.1      # Scale down velocity targets
OUTPUT_SCALE=0.1        # Scale down model outputs  
TARGET_NORM_SCALE=1.0   # Keep targets normalized

echo "‚öôÔ∏è FIXED Training Configuration:"
echo "   Mode: $TRAINING_MODE"
echo "   Embeddings: $EMBEDDINGS_DIR"
echo "   Output: $OUTPUT_DIR"
echo "   Model: $MODEL_SIZE"
echo "   Batch size: $BATCH_SIZE"
echo "   Learning rate: $LEARNING_RATE"
echo "   Epochs: $NUM_EPOCHS"
echo "   üîß FIXES:"
echo "     ‚Ä¢ Velocity scale: $VELOCITY_SCALE"
echo "     ‚Ä¢ Output scale: $OUTPUT_SCALE"
echo "     ‚Ä¢ Target norm scale: $TARGET_NORM_SCALE"

# Verify embeddings directory exists
if [ ! -d "$EMBEDDINGS_DIR" ]; then
    echo "‚ùå Embeddings directory not found: $EMBEDDINGS_DIR"
    echo "Available directories in workspace:"
    ls -la "$WORKSPACE/embeddings/" || echo "No embeddings directory found"
    exit 1
fi

# Check for shard files
echo "üîç Checking for shard files..."
SHARD_FILES=$(find "$EMBEDDINGS_DIR" -name "embeddings_shard_*.pkl" | head -5)
if [ -z "$SHARD_FILES" ]; then
    echo "‚ùå No shard files found in $EMBEDDINGS_DIR"
    echo "Directory contents:"
    ls -la "$EMBEDDINGS_DIR"
    exit 1
else
    echo "‚úÖ Found shard files:"
    echo "$SHARD_FILES"
fi

# Check if we have the fixed training script
if [ ! -f "train_blip3o_enhanced.py" ]; then
    echo "‚ùå Fixed training script not found: train_blip3o_enhanced.py"
    echo "Available Python files:"
    ls -la *.py
    exit 1
else
    echo "‚úÖ Found fixed training script: train_blip3o_enhanced.py"
fi

# Launch FIXED training with proper scaling parameters
echo "üöÄ Starting FIXED Training Process..."
echo "Expected improvements:"
echo "  üìà Cosine similarity should improve from ~0.01 to >0.3"
echo "  üìä Prediction norms should align with target norms"
echo "  üìâ Loss should decrease smoothly"
echo "  üéØ Much better evaluation results"
echo ""

python train_blip3o_enhanced.py \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --training_mode "$TRAINING_MODE" \
    --model_size "$MODEL_SIZE" \
    --num_epochs $NUM_EPOCHS \
    --batch_size $BATCH_SIZE \
    --learning_rate $LEARNING_RATE \
    --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
    --logging_steps $LOGGING_STEPS \
    --save_steps $SAVE_STEPS \
    --velocity_scale $VELOCITY_SCALE \
    --output_scale $OUTPUT_SCALE \
    --target_norm_scale $TARGET_NORM_SCALE \
    --fp16

# Check training result
TRAINING_EXIT_CODE=$?

if [ $TRAINING_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ FIXED Training completed successfully!"
    echo "   Model saved to: $OUTPUT_DIR"
    echo "   Training mode: $TRAINING_MODE"
    echo "   Fixes applied: Velocity scaling, Output scaling, Norm alignment"
    echo ""
    echo "üìä Training Summary:"
    if [ -f "$OUTPUT_DIR/training_info_fixed.json" ]; then
        echo "Fixed training info saved to: $OUTPUT_DIR/training_info_fixed.json"
        # Show some key info
        python -c "
import json
try:
    with open('$OUTPUT_DIR/training_info_fixed.json', 'r') as f:
        info = json.load(f)
    print(f\"   Training mode: {info.get('training_mode', 'unknown')}\")
    print(f\"   Epochs completed: {info.get('total_epochs', 'unknown')}\")
    print(f\"   Total steps: {info.get('total_steps', 'unknown')}\")
    loss_stats = info.get('loss_statistics', {})
    if loss_stats:
        print(f\"   Final loss: {loss_stats.get('current_loss', 'unknown')}\")
        print(f\"   Loss trend: {loss_stats.get('loss_trend', 'unknown')}\")
    fixes = info.get('fixes_applied', {})
    if fixes:
        print(f\"   Velocity scale: {fixes.get('velocity_scale', 'unknown')}\")
        print(f\"   Output scale: {fixes.get('output_scale', 'unknown')}\")
        print(f\"   Adaptive scaling: {fixes.get('adaptive_scaling', 'unknown')}\")
except Exception as e:
    print(f\"   Could not read training info: {e}\")
"
    fi
    
    echo ""
    echo "üéØ Next Steps:"
    echo "1. Run the FIXED evaluation script:"
    echo "   python eval_blip3o_patch_similarity.py \\"
    echo "     --model_path $OUTPUT_DIR \\"
    echo "     --chunked_embeddings_dir $EMBEDDINGS_DIR \\"
    echo "     --training_mode $TRAINING_MODE \\"
    echo "     --same_data_eval \\"
    echo "     --normalize_embeddings"
    echo ""
    echo "2. Expected evaluation results:"
    echo "   ‚Ä¢ Overall cosine similarity: >0.3 (vs 0.01 before)"
    echo "   ‚Ä¢ High quality images: >30% (vs 0% before)"
    echo "   ‚Ä¢ Prediction norms: ~1.0 (vs 0.3 before)"
    echo "   ‚Ä¢ Target norms: ~1.0 (vs 32.0 before)"
    
else
    echo "‚ùå FIXED Training failed with exit code: $TRAINING_EXIT_CODE"
    echo "Check the error logs above for details"
    
    # Show some diagnostic info
    echo ""
    echo "üîç Diagnostic Information:"
    echo "Working directory: $(pwd)"
    echo "Python path:"
    python -c "import sys; print('\n'.join(sys.path))"
    echo ""
    echo "Available modules:"
    python -c "
try:
    import src.modules.models.blip3o_patch_dit
    print('‚úÖ Model module available')
except Exception as e:
    print(f'‚ùå Model module: {e}')

try:
    import src.modules.losses.blip3o_flow_matching_loss
    print('‚úÖ FIXED Loss module available')
except Exception as e:
    print(f'‚ùå FIXED Loss module: {e}')

try:
    import src.modules.trainers.blip3o_training_only_trainer
    print('‚úÖ Trainer module available')
except Exception as e:
    print(f'‚ùå Trainer module: {e}')

try:
    import src.modules.datasets.blip3o_dataset
    print('‚úÖ Dataset module available')
except Exception as e:
    print(f'‚ùå Dataset module: {e}')
"
fi

echo ""
echo "üèÅ FIXED Training job completed at $(date)"
echo "Exit code: $TRAINING_EXIT_CODE"
echo ""
echo "üîß Fixes Applied in This Run:"
echo "  ‚úÖ Velocity scaling to address 50x norm mismatch"
echo "  ‚úÖ Output scaling in DiT model"
echo "  ‚úÖ Adaptive scaling mechanism in loss function"
echo "  ‚úÖ Proper rectified flow implementation"
echo "  ‚úÖ Fixed generation timestep schedule"
echo "  ‚úÖ Consistent normalization handling"

exit $TRAINING_EXIT_CODE