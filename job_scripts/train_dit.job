#!/bin/bash
#SBATCH --job-name=blip3o_training
#SBATCH --partition=gpu_a100
#SBATCH --nodes=1
#SBATCH --gpus=3
#SBATCH --ntasks=1
#SBATCH --cpus-per-gpu=9
#SBATCH --time=12:00:00
#SBATCH --mem=64GB
#SBATCH --output=./slurm_out/blip3o_training_%j.out
#SBATCH --error=./slurm_out/blip3o_training_%j.err

# =============================================================================
# BLIP3-o TRAINING-ONLY JOB SCRIPT
# Training only (no evaluation)
# =============================================================================

echo "üöÄ Starting BLIP3-o Training-Only Job"
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "============================================================"

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Workspace setup
export USER=$(whoami)
export JOB_ID=${SLURM_JOB_ID}
export WORKSPACE="/scratch-shared/${USER}/blip3o_workspace"
export EMBEDDINGS_DIR="${WORKSPACE}/embeddings"
export CHECKPOINTS="${WORKSPACE}/checkpoints"

# Configuration
TRAINING_MODE="patch_only"  # patch_only or cls_patch
EMBEDDINGS_DIR="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/patch_only_256_tokens"
OUTPUT_DIR="${CHECKPOINTS}/training_only_${TRAINING_MODE}_${JOB_ID}_$(date +%Y%m%d_%H%M%S)"
mkdir -p "${OUTPUT_DIR}"

# Training parameters
MODEL_SIZE="base"
NUM_EPOCHS=10
BATCH_SIZE=64
LEARNING_RATE=5e-5
GRADIENT_ACCUMULATION_STEPS=2
LOGGING_STEPS=5
SAVE_STEPS=100
SHARD_INDEX=0

echo "‚öôÔ∏è Training Configuration:"
echo "   Mode: $TRAINING_MODE"
echo "   Embeddings: $EMBEDDINGS_DIR"
echo "   Output: $OUTPUT_DIR"
echo "   Model: $MODEL_SIZE"
echo "   Batch size: $BATCH_SIZE"
echo "   Learning rate: $LEARNING_RATE"
echo "   Epochs: $NUM_EPOCHS"

# Launch training
echo "üöÄ Starting Training-Only Process..."
python train_blip3o_enhanced.py \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --training_mode "$TRAINING_MODE" \
    --shard_index $SHARD_INDEX \
    --model_size "$MODEL_SIZE" \
    --num_epochs $NUM_EPOCHS \
    --batch_size $BATCH_SIZE \
    --learning_rate $LEARNING_RATE \
    --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
    --logging_steps $LOGGING_STEPS \
    --save_steps $SAVE_STEPS \
    --fp16

# Handle completion
if [ $? -eq 0 ]; then
    echo "‚úÖ Training completed successfully!"
    echo "   Model saved to: $OUTPUT_DIR"
else
    echo "‚ùå Training failed!"
    exit 1
fi

echo "üèÅ Job completed at $(date)"
exit 0