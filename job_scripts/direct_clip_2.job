#!/bin/bash
#SBATCH --job-name=blip3o_recall_eval
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --cpus-per-gpu=18
#SBATCH --time=2:00:00
#SBATCH --mem=0
#SBATCH --output=./slurm_out/blip3o_recall_%j.out
#SBATCH --error=./slurm_out/blip3o_recall_%j.err

# =============================================================================
# BLIP3-o Recall Evaluation Job
# Tests both CLIP baseline and trained BLIP3-o model on COCO dataset
# =============================================================================

echo "üîç BLIP3-o Recall Evaluation"
echo "============================"

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

source activate eva_clip_env

# Configuration
COCO_ROOT="./data/coco"
BLIP3O_MODEL_PATH="/scratch-shared/scur2711/blip3o_workspace/checkpoints/blip3o_multi_gpu_fixed_cosine_13219643_20250719_081230"
NUM_SAMPLES=1000
DEVICE="cuda"
K_VALUES="1 5 10"
NUM_INFERENCE_STEPS=50

# Setup temp directories for model cache
export USER=$(whoami)
export JOB_ID=${SLURM_JOB_ID}
export JOB_TEMP="/scratch-local/${USER}.${JOB_ID}/blip3o_recall"

export TORCH_HOME="${JOB_TEMP}/torch"
export HF_HOME="${JOB_TEMP}/huggingface"
export TRANSFORMERS_CACHE="${JOB_TEMP}/transformers"

mkdir -p "${TORCH_HOME}" "${HF_HOME}" "${TRANSFORMERS_CACHE}"
mkdir -p ./slurm_out ./results

echo "Configuration:"
echo "  COCO Root: $COCO_ROOT"
echo "  BLIP3-o Model: $BLIP3O_MODEL_PATH"
echo "  Samples: $NUM_SAMPLES"
echo "  K values: $K_VALUES"
echo "  Inference steps: $NUM_INFERENCE_STEPS"
echo "  Device: $DEVICE"
echo "  Job ID: $JOB_ID"
echo "  Node: $SLURMD_NODENAME"

# Verify paths exist
echo ""
echo "üîç Verifying paths..."
echo "==================="

if [ ! -d "$COCO_ROOT" ]; then
    echo "‚ùå ERROR: COCO data not found at $COCO_ROOT"
    exit 1
fi

if [ ! -f "$COCO_ROOT/annotations/captions_val2017.json" ]; then
    echo "‚ùå ERROR: COCO annotations not found"
    exit 1
fi

if [ ! -d "$COCO_ROOT/images/val2017" ]; then
    echo "‚ùå ERROR: COCO images not found"
    exit 1
fi

if [ ! -d "$BLIP3O_MODEL_PATH" ]; then
    echo "‚ùå ERROR: BLIP3-o model not found at $BLIP3O_MODEL_PATH"
    echo "   Available checkpoints:"
    ls -la /scratch-shared/scur2711/blip3o_workspace/checkpoints/ 2>/dev/null || echo "   No checkpoints found"
    exit 1
fi

# Check for model files
if [ ! -f "$BLIP3O_MODEL_PATH/config.json" ] && [ ! -f "$BLIP3O_MODEL_PATH/blip3o_model_config.json" ]; then
    echo "‚ùå ERROR: No config file found in BLIP3-o model directory"
    echo "   Model directory contents:"
    ls -la "$BLIP3O_MODEL_PATH"
    exit 1
fi

if [ ! -f "$BLIP3O_MODEL_PATH/pytorch_model.bin" ] && [ ! -f "$BLIP3O_MODEL_PATH/model.safetensors" ] && [ ! -f "$BLIP3O_MODEL_PATH/pytorch_model.safetensors" ]; then
    echo "‚ùå ERROR: No model weights found in BLIP3-o model directory"
    echo "   Model directory contents:"
    ls -la "$BLIP3O_MODEL_PATH"
    exit 1
fi

echo "‚úÖ COCO data verified"
echo "‚úÖ BLIP3-o model verified"

# Show model info
echo ""
echo "üìä Model Information:"
echo "===================="
echo "Model path: $BLIP3O_MODEL_PATH"
echo "Model contents:"
ls -la "$BLIP3O_MODEL_PATH"

if [ -f "$BLIP3O_MODEL_PATH/training_summary.json" ]; then
    echo ""
    echo "Training summary:"
    cat "$BLIP3O_MODEL_PATH/training_summary.json" | head -20
fi

# Run recall evaluation
echo ""
echo "üöÄ Starting BLIP3-o Recall Evaluation..."
echo "======================================="
echo "This will test:"
echo "  1. üéØ CLIP ViT-L/14 baseline (for verification)"
echo "  2. ü§ñ Your trained BLIP3-o model"
echo ""
echo "Expected results:"
echo "  ‚Ä¢ CLIP baseline R@1: ~58-60% (literature)"
echo "  ‚Ä¢ BLIP3-o R@1: Should match or exceed baseline"
echo ""

EVAL_START_TIME=$(date +%s)

python comp_eval.py \
    --coco_root "$COCO_ROOT" \
    --blip3o_model_path "$BLIP3O_MODEL_PATH" \
    --num_samples $NUM_SAMPLES \
    --device $DEVICE \
    --k_values $K_VALUES \
    --num_inference_steps $NUM_INFERENCE_STEPS \
    --generation_mode auto
    --save_results "results/blip3o_recall_evaluation_${JOB_ID}.json"

EXIT_CODE=$?
EVAL_END_TIME=$(date +%s)
EVAL_DURATION=$((EVAL_END_TIME - EVAL_START_TIME))

# Results summary
echo ""
echo "========================================================================"
echo "üìä BLIP3-o RECALL EVALUATION RESULTS"
echo "========================================================================"
echo "Job ID: $JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Evaluation Duration: $EVAL_DURATION seconds"
echo "Total Runtime: $SECONDS seconds"
echo "Date: $(date)"

if [ $EXIT_CODE -eq 0 ]; then
    echo "Status: ‚úÖ SUCCESS - EVALUATION COMPLETED"
    
    # Find and display results from JSON file
    RESULTS_FILE="results/blip3o_recall_evaluation_${JOB_ID}.json"
    if [ -f "$RESULTS_FILE" ]; then
        echo ""
        echo "üìä DETAILED RESULTS SUMMARY:"
        echo "============================"
        
        # Parse JSON results and display prominently
        if command -v python3 &> /dev/null; then
            python3 << EOF
import json
import sys

try:
    with open('$RESULTS_FILE', 'r') as f:
        data = json.load(f)
    
    method_results = data.get('method_results', {})
    eval_info = data.get('evaluation_info', {})
    
    print()
    print("üéØ RECALL COMPARISON RESULTS:")
    print("-" * 50)
    
    # Check if we have both methods
    clip_results = method_results.get('clip_baseline', {})
    blip3o_results = method_results.get('blip3o', {})
    
    if 'error' not in clip_results and 'error' not in blip3o_results:
        # Both methods successful
        clip_r1 = clip_results.get('recall@1', 0) * 100
        clip_r5 = clip_results.get('recall@5', 0) * 100
        clip_r10 = clip_results.get('recall@10', 0) * 100
        
        blip3o_r1 = blip3o_results.get('recall@1', 0) * 100
        blip3o_r5 = blip3o_results.get('recall@5', 0) * 100
        blip3o_r10 = blip3o_results.get('recall@10', 0) * 100
        
        print(f"üìã CLIP BASELINE (ViT-L/14):")
        print(f"   R@1:  {clip_r1:5.1f}% | R@5:  {clip_r5:5.1f}% | R@10: {clip_r10:5.1f}%")
        print()
        print(f"ü§ñ BLIP3-o MODEL:")
        print(f"   R@1:  {blip3o_r1:5.1f}% | R@5:  {blip3o_r5:5.1f}% | R@10: {blip3o_r10:5.1f}%")
        print()
        
        # Performance comparison
        r1_diff = blip3o_r1 - clip_r1
        r1_pct_change = (r1_diff / clip_r1) * 100 if clip_r1 > 0 else 0
        
        print(f"üìà PERFORMANCE ANALYSIS:")
        print(f"   R@1 Difference: {r1_diff:+.1f}% ({r1_pct_change:+.1f}%)")
        
        if r1_diff >= 2:
            print(f"   üéâ EXCELLENT: BLIP3-o significantly outperforms CLIP!")
            print(f"   üéØ Your model successfully learned EVA‚ÜíCLIP mapping")
        elif r1_diff >= 0:
            print(f"   ‚úÖ GOOD: BLIP3-o matches or slightly exceeds CLIP")
            print(f"   üéØ Model preserves CLIP's retrieval capabilities")
        elif r1_diff >= -2:
            print(f"   ‚ö†Ô∏è  ACCEPTABLE: Minor performance drop")
            print(f"   üí° Consider fine-tuning or architectural improvements")
        else:
            print(f"   ‚ùå CONCERNING: Significant performance drop")
            print(f"   üí° Model needs architectural or training improvements")
        
        print()
        
        # Literature comparison
        print(f"üìö Literature Comparison:")
        print(f"   Expected CLIP ViT-L/14 R@1: ~58-60%")
        print(f"   Your CLIP baseline R@1:     {clip_r1:.1f}%")
        
        if clip_r1 >= 58:
            print(f"   ‚úÖ EXCELLENT: Baseline matches literature!")
        elif clip_r1 >= 55:
            print(f"   ‚úÖ GOOD: Close to literature values")
        else:
            print(f"   ‚ö†Ô∏è  LOW: Below expected literature values")
        
        print()
        
        # Overall assessment
        print(f"üéØ OVERALL ASSESSMENT:")
        print("-" * 30)
        
        if blip3o_r1 >= clip_r1 and clip_r1 >= 55:
            print("üéâ SUCCESS: Model training was successful!")
            print("   ‚úÖ BLIP3-o learned to generate good CLIP embeddings")
            print("   ‚úÖ Retrieval performance preserved or improved")
            print("   üöÄ Ready for deployment or further research")
        elif blip3o_r1 >= clip_r1 - 2 and clip_r1 >= 55:
            print("‚úÖ GOOD: Model shows promising results")
            print("   ‚úÖ BLIP3-o generates reasonable CLIP embeddings")
            print("   üí° Minor improvements possible with fine-tuning")
        else:
            print("‚ö†Ô∏è  NEEDS IMPROVEMENT: Results below expectations")
            print("   üí° Consider model architecture or training changes")
            print("   üí° Check loss curves and training stability")
    
    else:
        # Handle errors
        if 'error' in clip_results:
            print(f"‚ùå CLIP baseline failed: {clip_results['error']}")
        if 'error' in blip3o_results:
            print(f"‚ùå BLIP3-o evaluation failed: {blip3o_results['error']}")
    
    print()
    print(f"üíæ Full results saved to: $RESULTS_FILE")

except Exception as e:
    print(f"‚ùå Could not parse results file: {e}")
    sys.exit(1)
EOF
        else
            echo "‚ö†Ô∏è  Python not available to parse results"
            echo "   Results file: $RESULTS_FILE"
        fi
    else
        echo "‚ö†Ô∏è  No results file found"
        echo "   Evaluation may have completed without saving results"
        echo "   Check the output above for inline results"
    fi
    
    echo ""
    echo "‚úÖ BLIP3-o RECALL EVALUATION COMPLETED SUCCESSFULLY"
    
else
    echo "Status: ‚ùå FAILED"
    echo ""
    echo "‚ùå BLIP3-o RECALL EVALUATION FAILED WITH EXIT CODE: $EXIT_CODE"
    echo ""
    echo "üîç Troubleshooting:"
    echo "   1. Check if COCO data exists and is accessible"
    echo "   2. Verify BLIP3-o model path and files"
    echo "   3. Ensure GPU memory is sufficient"
    echo "   4. Check Python environment and dependencies"
    echo "   5. Look for error messages in the output above"
    echo ""
    echo "üìÇ Log files:"
    echo "   Output: ./slurm_out/blip3o_recall_${JOB_ID}.out"
    echo "   Error:  ./slurm_out/blip3o_recall_${JOB_ID}.err"
    echo ""
    echo "üîß Quick checks:"
    echo "   ‚Ä¢ COCO path: $COCO_ROOT"
    echo "   ‚Ä¢ BLIP3-o model: $BLIP3O_MODEL_PATH"
    echo "   ‚Ä¢ Available space: $(df -h . | tail -1 | awk '{print $4}')"
fi

echo ""
echo "========================================================================"
echo "üèÅ EVALUATION SUMMARY"
echo "========================================================================"

# Always show final status prominently
if [ $EXIT_CODE -eq 0 ]; then
    echo "üéâ SUCCESS: Check the recall results above!"
    echo ""
    echo "üìã What was tested:"
    echo "   ‚úÖ CLIP ViT-L/14 baseline (verification)"
    echo "   ‚úÖ Your trained BLIP3-o model"
    echo ""
    echo "üéØ Key Questions Answered:"
    echo "   ‚Ä¢ Does CLIP baseline match literature? (~58-60% expected)"
    echo "   ‚Ä¢ Does BLIP3-o preserve/improve recall performance?"
    echo "   ‚Ä¢ How well did the dual supervision training work?"
    echo ""
    echo "üìä Next Steps:"
    echo "   ‚Ä¢ Review the performance comparison above"
    echo "   ‚Ä¢ Check if results meet your requirements"
    echo "   ‚Ä¢ Use insights to guide further development"
else
    echo "‚ùå FAILURE: Check error messages above and in log files"
    echo ""
    echo "üí° Common Issues:"
    echo "   ‚Ä¢ BLIP3-o model path incorrect or files missing"
    echo "   ‚Ä¢ Insufficient GPU memory"
    echo "   ‚Ä¢ Missing dependencies or environment issues"
    echo "   ‚Ä¢ COCO dataset path or permissions problems"
fi

echo "========================================================================"

# Cleanup temp cache
if [ -d "${JOB_TEMP}" ]; then
    echo "üßπ Cleaning up temporary cache..."
    rm -rf "${JOB_TEMP}"
fi

echo "üèÅ Job completed at $(date)"

exit $EXIT_CODE