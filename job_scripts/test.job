#!/bin/bash
#SBATCH --job-name=test_gpu
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=3
#SBATCH --time=0:10:00
#SBATCH --output=./slurm_out/test_gpu_%j.out

module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

echo "=== Testing Single GPU ==="
python test_multi_gpu.py

echo "=== Testing Multi-GPU ==="
torchrun --nproc_per_node=3 test_multi_gpu.py