#!/bin/bash
#SBATCH --job-name=gpu_debug
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=3
#SBATCH --cpus-per-gpu=18
#SBATCH --time=0:30:00
#SBATCH --output=./gpu_debug_%j.out
#SBATCH --error=./gpu_debug_%j.err

echo "üîç GPU Debug Job Started"
echo "========================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Date: $(date)"

# Load modules
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0

echo "‚úÖ Modules loaded"

# Activate environment
source activate eva_clip_env
echo "‚úÖ Environment activated"

# Show environment
echo ""
echo "üìä Environment Check:"
echo "CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"
echo "SLURM_GPUS: $SLURM_GPUS"
echo "SLURM_GPUS_ON_NODE: $SLURM_GPUS_ON_NODE"

# Run diagnostics
echo ""
echo "üß™ Running GPU diagnostics..."
python gpu_diagnostics.py

echo ""
echo "üîç Testing simple GPU operations..."
python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU count: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
        x = torch.randn(100, 100, device=f'cuda:{i}')
        print(f'  ‚úÖ GPU {i} working')
else:
    print('‚ùå No CUDA available')
"

echo ""
echo "üèÅ Debug job completed"
