# EVA-CLIP Flow Matching Project Requirements
# Phase 1: Dataset Loading and Feature Extraction
#
# SETUP INSTRUCTIONS:
# 1. Create virtual environment: python3 -m venv eva_clip_env
# 2. Activate environment: source eva_clip_env/bin/activate  
# 3. Install requirements: pip install -r requirements.txt
# 4. Test setup: python -c "import torch; print('âœ… Setup complete!')"

# Core PyTorch framework
torch>=2.5.1
torchvision>=0.20.1
numpy>=1.26.0  # Updated for Python 3.12 compatibility

# Hugging Face ecosystem for models and datasets
transformers>=4.30.0
datasets>=2.10.0
huggingface_hub>=0.15.0

# Data handling and processing
webdataset>=0.2.0
pillow>=9.0.0
tqdm==4.65.0

# BLIP3-o DiT Training Requirements
# Core deep learning dependencies

# PyTorch ecosystem
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0

# HuggingFace ecosystem
transformers>=4.35.0
diffusers>=0.24.0
accelerate>=0.24.0
safetensors>=0.4.0
datasets>=2.14.0
tokenizers>=0.14.0
huggingface-hub>=0.17.0

# Scientific computing
numpy>=1.21.0
scipy>=1.9.0
scikit-learn>=1.1.0

# Data processing
pillow>=8.3.0
opencv-python>=4.5.0

# Logging and monitoring
wandb>=0.15.0
tensorboard>=2.10.0

# Progress and utilities
tqdm>=4.64.0
rich>=12.0.0
click>=8.0.0

# Visualization
matplotlib>=3.5.0
seaborn>=0.11.0

# File handling and serialization
pickle5>=0.0.11; python_version < "3.8"
joblib>=1.2.0
pyarrow>=9.0.0

# Configuration management
omegaconf>=2.3.0

# JSON improvements
ujson>=5.4.0

# System monitoring
psutil>=5.9.0

# Performance monitoring (GPU)
py3nvml>=0.2.7

# Optional: Memory-efficient attention (uncomment if you have compatible CUDA)
# xformers>=0.0.20

# Development tools (optional)
# jupyter>=1.0.0
# ipywidgets>=7.7.0
# black>=22.0.0
# flake8>=4.0.0
# pytest>=7.0.0

# Compatibility
typing-extensions>=4.3.0
pathlib2>=2.3.7; python_version < "3.4"