"""
Pure BLIP3-o Flow Matching Loss - Paper Aligned (No Contrastive Loss)
src/modules/losses/blip3o_flow_matching_loss.py

CHANGES:
1. Removed ALL contrastive loss components
2. Keep ONLY flow matching loss as in BLIP3-o paper
3. Simplified implementation focused on velocity prediction
4. Support for both 256 and 257 token modes (CLS+patch and patch-only)
5. Detailed metrics for training monitoring
6. Per-patch, per-image, and global similarity analysis
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any, Tuple
import math
import logging

logger = logging.getLogger(__name__)


class BLIP3oFlowMatchingLoss(nn.Module):
    """
    Pure Flow Matching Loss for BLIP3-o (Paper-aligned, NO contrastive loss)
    
    Only uses flow matching loss without any contrastive components.
    This follows the original BLIP3-o paper implementation.
    """
    
    def __init__(
        self,
        sigma_min: float = 1e-4,
        sigma_max: float = 1.0,
        prediction_type: str = "velocity",
        normalize_targets: bool = True,
    ):
        super().__init__()
        
        self.sigma_min = sigma_min
        self.sigma_max = sigma_max
        self.prediction_type = prediction_type
        self.normalize_targets = normalize_targets
        
        # EMA tracking for metrics
        self.register_buffer('ema_loss', torch.tensor(0.0))
        self.register_buffer('ema_cosine_sim', torch.tensor(0.0))
        self.ema_decay = 0.99
        
        logger.info(f"âœ… Pure BLIP3-o Flow Matching Loss initialized")
        logger.info(f"   Prediction type: {prediction_type}")
        logger.info(f"   Paper-aligned: ONLY flow matching loss")
        logger.info(f"   NO contrastive loss components")
        logger.info(f"   Supports both 256 and 257 token modes")

    def sample_timesteps(self, batch_size: int, device: torch.device) -> torch.Tensor:
        """Sample random timesteps for flow matching"""
        return torch.rand(batch_size, device=device, dtype=torch.float32)

    def get_noise_schedule(self, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """Get noise schedule parameters for flow matching"""
        # Linear schedule for rectified flow (BLIP3-o paper)
        alpha_t = t
        sigma_t = self.sigma_min + (self.sigma_max - self.sigma_min) * (1 - t)
        return alpha_t, sigma_t

    def interpolate_data(
        self,
        x_0: torch.Tensor,  # Source (noise) [B, N, 1024]
        x_1: torch.Tensor,  # Target CLIP embeddings [B, N, 1024]
        t: torch.Tensor,    # Timesteps [B]
        noise: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        Interpolate between source and target (rectified flow)
        
        Args:
            x_0: Source noise [B, N, 1024] where N is 256 or 257
            x_1: Target embeddings [B, N, 1024]
            t: Timesteps [B]
            noise: Additional noise (optional)
            
        Returns:
            Interpolated state [B, N, 1024]
        """
        if noise is None:
            noise = torch.zeros_like(x_1)
        
        # Ensure proper shapes for broadcasting
        t = t.view(-1, 1, 1)  # [B, 1, 1]
        
        alpha_t, sigma_t = self.get_noise_schedule(t.squeeze(-1))
        alpha_t = alpha_t.view(-1, 1, 1)
        sigma_t = sigma_t.view(-1, 1, 1)
        
        # Ensure x_0 requires gradients for proper flow
        if not x_0.requires_grad:
            x_0 = x_0.detach().requires_grad_(True)
        
        # Linear interpolation (rectified flow)
        x_t = (1 - alpha_t) * x_0 + alpha_t * x_1.detach() + sigma_t * noise
        
        # Verify output requires gradients
        if not x_t.requires_grad:
            x_t = x_t.requires_grad_(True)
            logger.warning("Fixed gradient requirement on interpolated output")
        
        return x_t

    def compute_velocity_target(
        self,
        x_0: torch.Tensor,  # Source [B, N, 1024]
        x_1: torch.Tensor,  # Target [B, N, 1024]
        t: torch.Tensor,    # Timesteps [B]
        noise: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        Compute velocity target for flow matching (BLIP3-o paper)
        
        For rectified flow, the velocity target is x_1 - x_0
        """
        if self.prediction_type == "velocity":
            # Rectified flow velocity (paper implementation)
            velocity_target = x_1.detach() - x_0.detach()
        elif self.prediction_type == "epsilon":
            # Noise prediction target
            velocity_target = noise.detach() if noise is not None else torch.randn_like(x_1)
        else:
            raise ValueError(f"Unknown prediction type: {self.prediction_type}")
        
        return velocity_target

    def compute_detailed_similarities(
        self,
        predicted: torch.Tensor,        # [B, N, 1024] - Predicted velocity
        target: torch.Tensor,           # [B, N, 1024] - Target embeddings
        training_mode: str = "cls_patch"
    ) -> Dict[str, torch.Tensor]:
        """
        Compute detailed per-patch, per-image, and global similarities
        
        Args:
            predicted: Predicted velocity [B, N, 1024]
            target: Target samples [B, N, 1024]
            training_mode: "cls_patch" or "patch_only"
            
        Returns:
            Dictionary with detailed similarity metrics
        """
        batch_size, num_tokens, dim = predicted.shape
        
        # Normalize for cosine similarity
        pred_norm = F.normalize(predicted, p=2, dim=-1)
        target_norm = F.normalize(target, p=2, dim=-1)
        
        # Per-patch cosine similarities [B, N]
        per_patch_sim = F.cosine_similarity(pred_norm, target_norm, dim=-1)
        
        # Per-image average similarities [B]
        per_image_avg_sim = per_patch_sim.mean(dim=1)
        
        # Global average similarity
        global_avg_sim = per_image_avg_sim.mean()
        
        similarities = {
            'per_patch_cosine': per_patch_sim,              # [B, N]
            'per_image_avg_cosine': per_image_avg_sim,      # [B]
            'global_avg_cosine': global_avg_sim,            # scalar
            'per_patch_mean': per_patch_sim.mean(),         # scalar
            'per_patch_std': per_patch_sim.std(),           # scalar
            'per_image_std': per_image_avg_sim.std(),       # scalar
        }
        
        # Mode-specific analysis
        if training_mode == "cls_patch" and num_tokens == 257:
            # Separate CLS and patch analysis
            cls_sim = per_patch_sim[:, 0]  # [B] - CLS token similarities
            patch_sim = per_patch_sim[:, 1:]  # [B, 256] - Patch similarities
            
            similarities.update({
                'cls_cosine': cls_sim.mean(),                    # scalar
                'cls_std': cls_sim.std(),                        # scalar
                'patch_cosine': patch_sim.mean(),                # scalar
                'patch_std': patch_sim.std(),                    # scalar
                'cls_vs_patch_correlation': torch.corrcoef(torch.stack([
                    cls_sim, patch_sim.mean(dim=1)
                ]))[0, 1] if batch_size > 1 else torch.tensor(0.0),
            })
        else:
            # Patch-only mode
            similarities.update({
                'cls_cosine': torch.tensor(0.0),  # Not applicable
                'patch_cosine': per_patch_sim.mean(),
                'patch_std': per_patch_sim.std(),
            })
        
        return similarities

    def forward(
        self,
        model_output: torch.Tensor,       # [B, N, 1024] - Predicted velocity (N=256 or 257)
        target_samples: torch.Tensor,     # [B, N, 1024] - Target CLIP embeddings
        timesteps: torch.Tensor,          # [B] - Timesteps
        eva_conditioning: torch.Tensor,   # [B, N, 4096] - EVA features (for metrics)
        noise: Optional[torch.Tensor] = None,
        return_metrics: bool = False,
        training_mode: str = "cls_patch",
    ) -> Tuple[torch.Tensor, Optional[Dict[str, float]]]:
        """
        Compute pure BLIP3-o flow matching loss (NO contrastive loss)
        
        Args:
            model_output: Predicted velocity [B, N, 1024]
            target_samples: Target CLIP embeddings [B, N, 1024] 
            timesteps: Flow matching timesteps [B]
            eva_conditioning: EVA features [B, N, 4096] (for metrics only)
            noise: Noise for flow matching
            return_metrics: Whether to return detailed metrics
            training_mode: "cls_patch" or "patch_only"
            
        Returns:
            (loss, metrics) - Pure flow matching loss only
        """
        batch_size = model_output.shape[0]
        num_tokens = model_output.shape[1]  # 256 or 257
        device = model_output.device
        
        # Verify model output has gradients
        if not model_output.requires_grad:
            logger.error("CRITICAL: Model output doesn't require gradients!")
            raise RuntimeError("Model output doesn't require gradients - training is broken!")
        
        # Input validation
        assert model_output.shape == target_samples.shape, \
            f"Shape mismatch: {model_output.shape} vs {target_samples.shape}"
        assert num_tokens in [256, 257], f"Expected 256 or 257 tokens, got {num_tokens}"
        assert model_output.shape[2] == 1024, f"Expected 1024-dim, got {model_output.shape[2]}"
        assert timesteps.shape[0] == batch_size, \
            f"Timestep batch size mismatch: {timesteps.shape[0]} vs {batch_size}"
        
        # Normalize targets if requested
        if self.normalize_targets:
            target_samples = F.normalize(target_samples.detach(), p=2, dim=-1)
        else:
            target_samples = target_samples.detach()
        
        # Create source distribution with gradients
        x_0 = torch.randn_like(target_samples, requires_grad=True)
        
        # Sample noise if not provided
        if noise is None:
            noise = torch.randn_like(target_samples) * 0.1
        
        # Compute velocity target (detached from gradients)
        velocity_target = self.compute_velocity_target(x_0, target_samples, timesteps, noise)
        
        # PURE FLOW MATCHING LOSS ONLY (no contrastive loss)
        flow_matching_loss = F.mse_loss(model_output, velocity_target, reduction='mean')
        
        # Verify loss has gradients
        if not flow_matching_loss.requires_grad:
            logger.error("CRITICAL: Flow matching loss doesn't require gradients!")
            raise RuntimeError("Flow matching loss doesn't require gradients!")
        
        # Total loss is ONLY the flow matching loss (paper-aligned)
        total_loss = flow_matching_loss
        
        # Update EMA metrics
        with torch.no_grad():
            self.ema_loss = self.ema_decay * self.ema_loss + (1 - self.ema_decay) * total_loss.item()
            
            # Compute cosine similarity for monitoring
            pred_flat = model_output.view(batch_size, -1)
            target_flat = velocity_target.view(batch_size, -1)
            cosine_sim = F.cosine_similarity(pred_flat, target_flat, dim=-1).mean()
            self.ema_cosine_sim = self.ema_decay * self.ema_cosine_sim + (1 - self.ema_decay) * cosine_sim.item()
        
        # Prepare metrics
        metrics = None
        if return_metrics:
            with torch.no_grad():
                # Compute detailed similarities
                detailed_sims = self.compute_detailed_similarities(
                    model_output, target_samples, training_mode
                )
                
                # Compute prediction quality metrics
                pred_norm = torch.norm(model_output, dim=-1).mean()
                target_norm = torch.norm(velocity_target, dim=-1).mean()
                
                # Quality indicators
                high_quality_patches = (detailed_sims['per_patch_cosine'] > 0.7).float().mean()
                very_high_quality_patches = (detailed_sims['per_patch_cosine'] > 0.8).float().mean()
                excellent_quality_patches = (detailed_sims['per_patch_cosine'] > 0.9).float().mean()
                
                high_quality_images = (detailed_sims['per_image_avg_cosine'] > 0.7).float().mean()
                very_high_quality_images = (detailed_sims['per_image_avg_cosine'] > 0.8).float().mean()
                excellent_quality_images = (detailed_sims['per_image_avg_cosine'] > 0.9).float().mean()
                
                # Estimate recall performance (for overfitting monitoring)
                estimated_recall = torch.clamp(detailed_sims['global_avg_cosine'] * 60, 0, 60)
                
                metrics = {
                    # Loss components (ONLY flow matching)
                    'flow_matching_loss': flow_matching_loss.item(),
                    'total_loss': total_loss.item(),
                    'contrastive_loss': 0.0,  # Not used in pure BLIP3-o
                    
                    # Detailed similarity metrics
                    'per_patch_mean_cosine': detailed_sims['per_patch_mean'].item(),
                    'per_patch_std_cosine': detailed_sims['per_patch_std'].item(),
                    'per_image_mean_cosine': detailed_sims['per_image_avg_cosine'].mean().item(),
                    'per_image_std_cosine': detailed_sims['per_image_std'].item(),
                    'global_mean_cosine': detailed_sims['global_avg_cosine'].item(),
                    
                    # Velocity prediction quality
                    'velocity_cosine_sim': cosine_sim.item(),
                    'prediction_norm': pred_norm.item(),
                    'target_norm': target_norm.item(),
                    
                    # Mode-specific metrics
                    'num_tokens': num_tokens,
                    'mode': 'cls_patch' if num_tokens == 257 else 'patch_only',
                    'cls_cosine_sim': detailed_sims['cls_cosine'].item(),
                    'patch_cosine_sim': detailed_sims['patch_cosine'].item(),
                    'patch_std': detailed_sims['patch_std'].item(),
                    
                    # Quality distribution
                    'high_quality_patches_ratio': high_quality_patches.item(),
                    'very_high_quality_patches_ratio': very_high_quality_patches.item(),
                    'excellent_quality_patches_ratio': excellent_quality_patches.item(),
                    'high_quality_images_ratio': high_quality_images.item(),
                    'very_high_quality_images_ratio': very_high_quality_images.item(),
                    'excellent_quality_images_ratio': excellent_quality_images.item(),
                    
                    # Performance indicators (for overfitting detection)
                    'estimated_recall_at_1': estimated_recall.item(),
                    'training_quality': (
                        'excellent' if detailed_sims['global_avg_cosine'] > 0.8 else
                        'very_good' if detailed_sims['global_avg_cosine'] > 0.7 else
                        'good' if detailed_sims['global_avg_cosine'] > 0.6 else
                        'fair' if detailed_sims['global_avg_cosine'] > 0.4 else
                        'needs_improvement'
                    ),
                    
                    # EMA metrics
                    'ema_loss': self.ema_loss.item(),
                    'ema_cosine_sim': self.ema_cosine_sim.item(),
                    
                    # Training diagnostics
                    'timestep_mean': timesteps.mean().item(),
                    'noise_level': torch.norm(noise, dim=-1).mean().item() if noise is not None else 0.0,
                    'batch_size': batch_size,
                    
                    # Gradient flow status
                    'gradient_flow_ok': True,
                    'model_output_has_grad': model_output.requires_grad,
                    'loss_has_grad': total_loss.requires_grad,
                    
                    # Paper alignment confirmation
                    'paper_aligned': True,
                    'loss_type': 'pure_flow_matching_only',
                    'contrastive_loss_used': False,
                    'blip3o_paper_compliant': True,
                }
                
                # Add mode-specific correlations
                if training_mode == "cls_patch" and num_tokens == 257:
                    if 'cls_vs_patch_correlation' in detailed_sims:
                        metrics['cls_vs_patch_correlation'] = detailed_sims['cls_vs_patch_correlation'].item()
        
        return total_loss, metrics


def create_blip3o_flow_matching_loss(
    prediction_type: str = "velocity",
    normalize_targets: bool = True,
    **kwargs
) -> BLIP3oFlowMatchingLoss:
    """
    Factory function for creating pure BLIP3-o flow matching loss
    
    Args:
        prediction_type: "velocity" (recommended) or "epsilon"
        normalize_targets: Whether to normalize target embeddings
        **kwargs: Additional arguments
        
    Returns:
        Pure BLIP3oFlowMatchingLoss instance (no contrastive loss)
    """
    return BLIP3oFlowMatchingLoss(
        prediction_type=prediction_type,
        normalize_targets=normalize_targets,
        **kwargs
    )


# Backward compatibility
create_flow_matching_loss = create_blip3o_flow_matching_loss