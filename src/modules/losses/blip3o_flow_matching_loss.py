#!/usr/bin/env python3
"""
COMPLETELY FIXED: BLIP3-o Flow Matching Loss - Aligned with BLIP3-o Paper
src/modules/losses/blip3o_flow_matching_loss.py

KEY FIXES:
1. Removed double scaling issue
2. Proper normalization as per BLIP3-o paper
3. Simplified and stable loss computation
4. Correct rectified flow implementation
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any, Tuple
import math
import logging

logger = logging.getLogger(__name__)


class BLIP3oFlowMatchingLoss(nn.Module):
    """
    FIXED: BLIP3-o Flow Matching Loss aligned with the paper
    
    Key principles from BLIP3-o paper:
    1. Generate normalized CLIP embeddings from EVA-CLIP features
    2. Use rectified flow for stable training
    3. Proper patch-level flow matching
    4. Target embeddings should be L2-normalized for retrieval
    """
    
    def __init__(
        self,
        prediction_type: str = "velocity",
        normalize_targets: bool = True,
        flow_type: str = "rectified",
        # REMOVED problematic scaling parameters
        ema_decay: float = 0.99,
        clip_norm_max: float = 10.0,  # Gradient clipping for stability
    ):
        super().__init__()
        
        self.prediction_type = prediction_type
        self.normalize_targets = normalize_targets
        self.flow_type = flow_type
        self.ema_decay = ema_decay
        self.clip_norm_max = clip_norm_max
        
        # EMA tracking for metrics (no scaling issues)
        self.register_buffer('ema_loss', torch.tensor(0.0))
        self.register_buffer('ema_velocity_cosine', torch.tensor(0.0))
        self.register_buffer('ema_pred_norm', torch.tensor(1.0))
        self.register_buffer('ema_target_norm', torch.tensor(1.0))
        
        # Training progress tracking
        self.register_buffer('best_velocity_sim', torch.tensor(0.0))
        self.register_buffer('training_steps', torch.tensor(0.0))
        
        logger.info(f"âœ… FIXED BLIP3-o Flow Matching Loss (BLIP3-o Paper Aligned)")
        logger.info(f"   Normalize targets: {normalize_targets}")
        logger.info(f"   Flow type: {flow_type}")
        logger.info(f"   Prediction type: {prediction_type}")

    def forward(
        self,
        model_output: torch.Tensor,  # [B, N, 1024] - Model's velocity prediction
        target_samples: torch.Tensor,  # [B, N, 1024] - Ground truth CLIP embeddings
        timesteps: torch.Tensor,  # [B] - Flow matching timesteps
        eva_conditioning: torch.Tensor,  # [B, N, 4096] - EVA-CLIP conditioning
        noise: Optional[torch.Tensor] = None,
        return_metrics: bool = False,
        training_mode: str = "patch_only",
    ) -> Tuple[torch.Tensor, Optional[Dict[str, float]]]:
        """
        FIXED: Clean flow matching loss computation following BLIP3-o paper
        """
        
        batch_size, num_tokens, embed_dim = model_output.shape
        device = model_output.device
        is_training = model_output.requires_grad
        
        # Input validation
        assert model_output.shape == target_samples.shape, \
            f"Shape mismatch: {model_output.shape} vs {target_samples.shape}"
        assert num_tokens in [256, 257], f"Expected 256 or 257 tokens, got {num_tokens}"
        assert embed_dim == 1024, f"Expected 1024-dim embeddings, got {embed_dim}"
        
        # BLIP3-o paper: Normalize target embeddings for retrieval tasks
        if self.normalize_targets:
            target_normalized = F.normalize(target_samples.detach(), p=2, dim=-1)
        else:
            target_normalized = target_samples.detach()
        
        # Create noise (source distribution)
        if noise is None:
            noise = torch.randn_like(target_normalized, device=device)
        else:
            noise = noise.detach()
        
        # RECTIFIED FLOW: Simple linear interpolation
        # x_t = (1-t) * x_0 + t * x_1, where x_0=noise, x_1=target
        t_expanded = timesteps.view(-1, 1, 1)  # [B, 1, 1]
        x_t = (1 - t_expanded) * noise + t_expanded * target_normalized
        
        # RECTIFIED FLOW VELOCITY TARGET: v = x_1 - x_0 = target - noise
        velocity_target = target_normalized - noise
        
        # SIMPLE MSE LOSS (no scaling complications)
        flow_loss = F.mse_loss(model_output, velocity_target, reduction='mean')
        
        # Gradient clipping for stability
        if is_training and flow_loss.requires_grad:
            # Clip gradients to prevent exploding gradients
            torch.nn.utils.clip_grad_norm_(model_output, self.clip_norm_max)
        
        # Prepare metrics
        metrics = None
        if return_metrics:
            with torch.no_grad():
                self.training_steps += 1
                
                # Compute velocity cosine similarity (training metric)
                pred_norm = F.normalize(model_output.detach(), p=2, dim=-1)
                target_norm = F.normalize(velocity_target.detach(), p=2, dim=-1)
                
                per_patch_cos = F.cosine_similarity(pred_norm, target_norm, dim=-1)
                per_image_cos = per_patch_cos.mean(dim=1)
                velocity_cosine_sim = per_image_cos.mean().item()
                
                # Compute norms for monitoring
                pred_norm_scalar = torch.norm(model_output.detach(), dim=-1).mean().item()
                target_norm_scalar = torch.norm(velocity_target.detach(), dim=-1).mean().item()
                
                # Update EMA metrics
                self.ema_loss = self.ema_decay * self.ema_loss + (1 - self.ema_decay) * flow_loss.item()
                self.ema_velocity_cosine = self.ema_decay * self.ema_velocity_cosine + (1 - self.ema_decay) * velocity_cosine_sim
                self.ema_pred_norm = self.ema_decay * self.ema_pred_norm + (1 - self.ema_decay) * pred_norm_scalar
                self.ema_target_norm = self.ema_decay * self.ema_target_norm + (1 - self.ema_decay) * target_norm_scalar
                
                # Track best similarity
                if velocity_cosine_sim > self.best_velocity_sim.item():
                    self.best_velocity_sim = torch.tensor(velocity_cosine_sim, device=device)
                
                # Quality metrics
                high_quality_patches = (per_patch_cos > 0.7).float().mean().item()
                very_high_quality_patches = (per_patch_cos > 0.8).float().mean().item()
                high_quality_images = (per_image_cos > 0.7).float().mean().item()
                
                metrics = {
                    # Core loss
                    'flow_matching_loss': flow_loss.item(),
                    'total_loss': flow_loss.item(),
                    
                    # Velocity similarity (training metric)
                    'velocity_cosine_sim': velocity_cosine_sim,
                    'velocity_per_patch_mean': per_patch_cos.mean().item(),
                    'velocity_per_patch_std': per_patch_cos.std().item(),
                    'velocity_per_image_mean': per_image_cos.mean().item(),
                    'velocity_high_quality_patches': high_quality_patches,
                    'velocity_very_high_quality_patches': very_high_quality_patches,
                    'velocity_high_quality_images': high_quality_images,
                    
                    # Norm tracking (should be similar now)
                    'prediction_norm': pred_norm_scalar,
                    'target_norm': target_norm_scalar,
                    'norm_ratio': target_norm_scalar / max(pred_norm_scalar, 1e-8),
                    
                    # EMA metrics
                    'ema_velocity_cosine': self.ema_velocity_cosine.item(),
                    'ema_pred_norm': self.ema_pred_norm.item(),
                    'ema_target_norm': self.ema_target_norm.item(),
                    'best_velocity_sim': self.best_velocity_sim.item(),
                    
                    # Training info
                    'training_steps': self.training_steps.item(),
                    'flow_type': self.flow_type,
                    'prediction_type': self.prediction_type,
                    'normalize_targets': self.normalize_targets,
                    'is_training': is_training,
                    'num_tokens': num_tokens,
                    'mode': training_mode,
                    
                    # FIXED: No more scaling confusion
                    'scaling_fixed': True,
                    'double_scaling_removed': True,
                }
        
        return flow_loss, metrics

    def get_training_info(self) -> Dict[str, float]:
        """Get current training information"""
        return {
            'ema_loss': self.ema_loss.item(),
            'ema_velocity_cosine': self.ema_velocity_cosine.item(),
            'ema_pred_norm': self.ema_pred_norm.item(),
            'ema_target_norm': self.ema_target_norm.item(),
            'best_velocity_sim': self.best_velocity_sim.item(),
            'training_steps': self.training_steps.item(),
            'flow_type': self.flow_type,
            'prediction_type': self.prediction_type,
            'normalize_targets': self.normalize_targets,
        }


def create_blip3o_flow_matching_loss(
    prediction_type: str = "velocity",
    normalize_targets: bool = True,
    flow_type: str = "rectified",
    **kwargs
) -> BLIP3oFlowMatchingLoss:
    """
    Factory function for FIXED flow matching loss
    """
    return BLIP3oFlowMatchingLoss(
        prediction_type=prediction_type,
        normalize_targets=normalize_targets,
        flow_type=flow_type,
        **kwargs
    )